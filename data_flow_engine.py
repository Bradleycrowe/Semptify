"""
Semptify Data Flow Engine

The Calendar is the central hub - all module data flows through it.
Every action, document, and decision routes through calendar with:
- Timestamps (when)
- Registry (who/what/why/context)
- Data processing (logical rules/reactions)
- Document IDs (file references)
- Function references (which function triggered it)
"""

import os
import json
import hashlib
import time
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from pathlib import Path
import threading

from ledger_calendar import get_ledger, get_calendar, LedgerEntry, CalendarEvent


class DataFlowRegistry:
    """Registry of all functions and their document/data relationships."""

    def __init__(self):
        self.functions: Dict[str, Dict[str, Any]] = {}
        self._lock = threading.Lock()

    def register_function(
        self,
        func_name: str,
        module: str,
        input_type: str,  # "document", "payment", "complaint", "evidence", "action"
        output_type: str,
        description: str,
        handler: Optional[Callable] = None,
    ) -> None:
        """Register a function that processes data through the flow."""
        with self._lock:
            self.functions[func_name] = {
                "module": module,
                "input_type": input_type,
                "output_type": output_type,
                "description": description,
                "handler": handler,
                "registered_at": time.time(),
            }

    def get_function(self, func_name: str) -> Optional[Dict[str, Any]]:
        """Get function metadata."""
        return self.functions.get(func_name)

    def list_functions(
        self, module: Optional[str] = None, input_type: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """List registered functions with optional filters."""
        results = list(self.functions.values())
        if module:
            results = [f for f in results if f["module"] == module]
        if input_type:
            results = [f for f in results if f["input_type"] == input_type]
        return results


class DocumentReference:
    """Reference to a document in the data flow."""

    def __init__(
        self,
        doc_id: str,
        doc_type: str,  # "lease", "receipt", "notice", "complaint", "evidence"
        file_path: str,
        owner_id: str,
        context: Dict[str, Any],
    ):
        self.doc_id = doc_id
        self.doc_type = doc_type
        self.file_path = file_path
        self.owner_id = owner_id
        self.context = context
        self.hash = self._compute_hash()
        self.created_at = datetime.now()
        self.processed_by: List[str] = []  # Functions that processed this doc

    def _compute_hash(self) -> str:
        """Compute SHA256 of document."""
        if os.path.exists(self.file_path):
            with open(self.file_path, "rb") as f:
                return hashlib.sha256(f.read()).hexdigest()
        return ""

    def add_processing(self, function_name: str) -> None:
        """Record that a function processed this document."""
        self.processed_by.append(function_name)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "doc_id": self.doc_id,
            "doc_type": self.doc_type,
            "file_path": self.file_path,
            "owner_id": self.owner_id,
            "context": self.context,
            "hash": self.hash,
            "created_at": self.created_at.isoformat(),
            "processed_by": self.processed_by,
        }


class DataFlowEvent:
    """An event in the data flow - actionâ†’reaction linking."""

    def __init__(
        self,
        event_id: str,
        trigger_function: str,  # Function that triggered this
        input_doc_id: Optional[str],  # Document that triggered it
        action_type: str,  # "upload", "process", "notify", "generate", "suggest"
        actor: str,  # Who triggered it
        reaction_type: str,  # What should happen
        reaction_data: Dict[str, Any],  # Data about the reaction
        calendar_event_id: Optional[str] = None,  # Linked calendar event
    ):
        self.event_id = event_id
        self.timestamp = datetime.now()
        self.trigger_function = trigger_function
        self.input_doc_id = input_doc_id
        self.action_type = action_type
        self.actor = actor
        self.reaction_type = reaction_type
        self.reaction_data = reaction_data
        self.calendar_event_id = calendar_event_id
        self.output_docs: List[str] = []  # Documents generated by this reaction

    def add_output_doc(self, doc_id: str) -> None:
        """Record a document generated by this flow event."""
        self.output_docs.append(doc_id)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "event_id": self.event_id,
            "timestamp": self.timestamp.isoformat(),
            "trigger_function": self.trigger_function,
            "input_doc_id": self.input_doc_id,
            "action_type": self.action_type,
            "actor": self.actor,
            "reaction_type": self.reaction_type,
            "reaction_data": self.reaction_data,
            "calendar_event_id": self.calendar_event_id,
            "output_docs": self.output_docs,
        }


class DataFlowEngine:
    """Central engine routing all data through calendar."""

    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.flow_file = self.data_dir / "data_flow.json"
        self.data_dir.mkdir(parents=True, exist_ok=True)

        self.registry = DataFlowRegistry()
        self.documents: Dict[str, DocumentReference] = {}
        self.flow_events: List[DataFlowEvent] = []
        self._lock = threading.Lock()

        self._load()

    def _load(self) -> None:
        """Load existing data flow from disk."""
        if self.flow_file.exists():
            try:
                with open(self.flow_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    # Reconstruct documents and events
                    for doc_dict in data.get("documents", []):
                        doc = DocumentReference(
                            doc_dict["doc_id"],
                            doc_dict["doc_type"],
                            doc_dict["file_path"],
                            doc_dict["owner_id"],
                            doc_dict["context"],
                        )
                        doc.processed_by = doc_dict.get("processed_by", [])
                        self.documents[doc.doc_id] = doc
            except Exception as e:
                print(f"Warning: Failed to load data flow: {e}")

    def register_module_functions(self, module_name: str, functions: List[Dict[str, Any]]) -> None:
        """Register all functions from a module.

        functions: List of dicts with:
        - name: function name
        - input_type: what it accepts
        - output_type: what it produces
        - description: what it does
        - handler: callable (optional)
        """
        for func in functions:
            self.registry.register_function(
                func_name=func["name"],
                module=module_name,
                input_type=func["input_type"],
                output_type=func["output_type"],
                description=func["description"],
                handler=func.get("handler"),
            )

    def process_document(
        self,
        doc_type: str,
        file_path: str,
        owner_id: str,
        context: Dict[str, Any],
        trigger_function: str,
        reaction_rules: Optional[List[Dict[str, Any]]] = None,
    ) -> tuple[DocumentReference, List[DataFlowEvent]]:
        """Process a document through the data flow.

        Returns: (DocumentReference, list of DataFlowEvents triggered)
        """
        # Create document reference
        doc_id = str(uuid.uuid4())
        doc_ref = DocumentReference(doc_id, doc_type, file_path, owner_id, context)
        doc_ref.add_processing(trigger_function)

        with self._lock:
            self.documents[doc_id] = doc_ref

        # Create flow event
        flow_event = DataFlowEvent(
            event_id=str(uuid.uuid4()),
            trigger_function=trigger_function,
            input_doc_id=None,
            action_type="upload",
            actor=owner_id,
            reaction_type="document_received",
            reaction_data={"doc_id": doc_id, "doc_type": doc_type},
        )

        # Log to ledger
        ledger = get_ledger()
        ledger_entry = LedgerEntry(
            entry_type=doc_type,
            actor=owner_id,
            data={
                "doc_id": doc_id,
                "function": trigger_function,
                "context": context,
            },
            files=[file_path],
        )
        ledger.add_entry(ledger_entry)
        flow_event.calendar_event_id = ledger_entry.id

        # Apply reaction rules
        reactions: List[DataFlowEvent] = []
        if reaction_rules:
            for rule in reaction_rules:
                reaction = self._apply_rule(rule, doc_ref, flow_event, owner_id)
                if reaction:
                    reactions.append(reaction)

        with self._lock:
            self.flow_events.append(flow_event)
            self.flow_events.extend(reactions)

        self._save()
        return doc_ref, [flow_event] + reactions

    def _apply_rule(
        self,
        rule: Dict[str, Any],
        doc_ref: DocumentReference,
        source_event: DataFlowEvent,
        actor: str,
    ) -> Optional[DataFlowEvent]:
        """Apply a reaction rule to a document."""
        condition = rule.get("condition")
        reaction = rule.get("reaction")

        # Check condition (simple pattern matching)
        if condition == "is_payment" and doc_ref.doc_type == "receipt":
            return self._create_reaction(
                trigger=source_event.event_id,
                reaction_type="update_ledger",
                data={"amount": doc_ref.context.get("amount"), "date": doc_ref.context.get("date")},
                actor=actor,
                input_doc_id=doc_ref.doc_id,
            )

        elif condition == "is_late_payment" and doc_ref.context.get("is_late"):
            return self._create_reaction(
                trigger=source_event.event_id,
                reaction_type="suggest_notice",
                data={"notice_type": "late_payment", "days_late": doc_ref.context.get("days_late")},
                actor=actor,
                input_doc_id=doc_ref.doc_id,
            )

        elif condition == "is_complaint" and doc_ref.doc_type == "complaint":
            return self._create_reaction(
                trigger=source_event.event_id,
                reaction_type="prepare_evidence_packet",
                data={"complaint_id": doc_ref.doc_id},
                actor=actor,
                input_doc_id=doc_ref.doc_id,
            )

        return None

    def _create_reaction(
        self,
        trigger: str,
        reaction_type: str,
        data: Dict[str, Any],
        actor: str,
        input_doc_id: Optional[str] = None,
    ) -> DataFlowEvent:
        """Create a reaction event."""
        event = DataFlowEvent(
            event_id=str(uuid.uuid4()),
            trigger_function=trigger,
            input_doc_id=input_doc_id,
            action_type="reaction",
            actor=actor,
            reaction_type=reaction_type,
            reaction_data=data,
        )

        # If reaction has a deadline, create calendar event
        if reaction_type == "suggest_notice":
            calendar = get_calendar()
            cal_event = CalendarEvent(
                title=f"Send {data.get('notice_type', 'notice')}",
                event_date=datetime.now() + timedelta(days=1),
                event_type="action_needed",
                description=f"Auto-suggested based on document: {input_doc_id}",
                related_entry_id=event.event_id,
                priority=2 if data.get("days_late", 0) > 7 else 1,
            )
            calendar.add_event(cal_event)
            event.calendar_event_id = cal_event.id

        return event

    def get_document_flow(self, doc_id: str) -> Dict[str, Any]:
        """Get complete flow history for a document."""
        doc_ref = self.documents.get(doc_id)
        if not doc_ref:
            return {"error": "Document not found"}

        # Find all flow events related to this document
        related_events = [
            e for e in self.flow_events if e.input_doc_id == doc_id or doc_id in e.output_docs
        ]

        return {
            "document": doc_ref.to_dict(),
            "flow_events": [e.to_dict() for e in related_events],
            "total_events": len(related_events),
        }

    def get_actor_flow(self, actor_id: str) -> Dict[str, Any]:
        """Get all data flow for a specific actor (user)."""
        actor_docs = [d for d in self.documents.values() if d.owner_id == actor_id]
        actor_events = [e for e in self.flow_events if e.actor == actor_id]

        return {
            "actor_id": actor_id,
            "documents_count": len(actor_docs),
            "documents": [d.to_dict() for d in actor_docs],
            "events_count": len(actor_events),
            "events": [e.to_dict() for e in actor_events],
        }

    def _save(self) -> None:
        """Save data flow to disk."""
        with self._lock:
            data = {
                "timestamp": datetime.now().isoformat(),
                "documents": [d.to_dict() for d in self.documents.values()],
                "events": [e.to_dict() for e in self.flow_events],
            }
            with open(self.flow_file, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2)


# Global instance
_flow_engine: Optional[DataFlowEngine] = None


def init_data_flow(data_dir: str = None) -> DataFlowEngine:
    """Initialize global data flow engine."""
    global _flow_engine
    if data_dir is None:
        data_dir = os.path.join(os.getcwd(), "data")
    _flow_engine = DataFlowEngine(data_dir)
    return _flow_engine


def get_data_flow() -> DataFlowEngine:
    """Get the global data flow engine."""
    global _flow_engine
    if _flow_engine is None:
        init_data_flow()
    return _flow_engine
