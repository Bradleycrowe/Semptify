Enter your prompt here

# Project Structure

├─ 📁 scripts
  └─ restart_all.sh
  └─ restart_all.ps1
  └─ sbom_vuln_delta.py
  └─ lint.sh
  └─ wsl_docker_verify.sh
  └─ wsl_setup.ps1
  └─ wsl_setup.sh
  └─ sbom_diff.py
├─ 📁 static
  ├─ 📁 css
    └─ admin.css
    └─ app.css
  ├─ 📁 js
    └─ service-worker.js
├─ 📁 .devcontainer
  └─ devcontainer.json
├─ 📁 docs
  └─ index.html
├─ 📁 tests
  └─ test_breakglass_and_ratelimit.py
  └─ test_token_rotation.py
  └─ test_csrf_enforced.py
  └─ test_admin_status.py
  └─ test_admin_enforced_mode.py
  └─ test_admin_open_mode.py
  └─ test_app.py
├─ 📁 .pytest_cache
  ├─ 📁 v
    ├─ 📁 cache
      └─ lastfailed
      └─ nodeids
  └─ README.md
  └─ CACHEDIR.TAG
├─ 📁 templates
  ├─ 📁 Saved Games
    └─ desktop.ini
  └─ sbom_list.html
  └─ release_history.html
  └─ index.html
  └─ admin.html
├─ 📁 security
  └─ vuln_allowlist.example.json
├─ 📁 logs
  └─ release-log.json
└─ requirements.txt
└─ .pre-commit-config.yaml
└─ RenderSmokeTest.ps1
└─ AllInOne-Push.ps1
└─ render.yaml
└─ PushAndDeploy-Semptify.ps1
└─ SemptifyCleanupGUI.py
└─ Push-Semptify.ps1
└─ Deploy-Semptify.ps1
└─ Semptify.py
└─ .releaserc.json
└─ docker-compose.yml
└─ .dockerignore
└─ Dockerfile
└─ RUNNING_PRODUCTION.md
└─ run_prod.py
└─ README.md


# Project Files

- .pre-commit-config.yaml
- .devcontainer\devcontainer.json
- RenderSmokeTest.ps1
- scripts\restart_all.ps1
- scripts\sbom_vuln_delta.py
- scripts\lint.sh
- scripts\wsl_docker_verify.sh
- scripts\wsl_setup.ps1
- scripts\wsl_setup.sh
- scripts\sbom_diff.py
- scripts\restart_all.sh
- static\js\service-worker.js
- static\css\app.css
- static\css\admin.css
- AllInOne-Push.ps1
- render.yaml
- PushAndDeploy-Semptify.ps1
- SemptifyCleanupGUI.py
- Push-Semptify.ps1
- Deploy-Semptify.ps1
- requirements.txt
- Semptify.py
- .releaserc.json
- docs\index.html
- docker-compose.yml
- .dockerignore
- Dockerfile
- RUNNING_PRODUCTION.md
- run_prod.py
- templates\sbom_list.html
- templates\release_history.html
- tests\test_breakglass_and_ratelimit.py
- templates\index.html
- templates\admin.html
- tests\test_token_rotation.py
- tests\test_csrf_enforced.py
- tests\test_admin_status.py
- tests\test_admin_enforced_mode.py
- tests\test_admin_open_mode.py
- tests\test_app.py
- .pytest_cache\CACHEDIR.TAG
- .pytest_cache\README.md
- templates\Saved Games\desktop.ini
- .pytest_cache\v\cache\lastfailed
- .pytest_cache\v\cache\nodeids
- README.md
- security\vuln_allowlist.example.json
- logs\release-log.json

## .pre-commit-config.yaml
```
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.6.8
    hooks:
      - id: ruff
        args: ["--fix"]
      - id: ruff-format
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.6.0
    hooks:
      - id: end-of-file-fixer
      - id: trailing-whitespace
  - repo: local
    hooks:
      - id: shellcheck
        name: shellcheck
        entry: bash -c 'command -v shellcheck >/dev/null 2>&1 && shellcheck scripts/*.sh || echo "[pre-commit] shellcheck skipped (not installed)"'
        language: system
        pass_filenames: false
```

## .devcontainer\devcontainer.json
```
{
  "name": "Semptify Dev",
  "image": "mcr.microsoft.com/devcontainers/python:3.13",
  "features": {
    "ghcr.io/devcontainers/features/git:1": {}
  },
  "postCreateCommand": "pip install --upgrade pip && pip install -r requirements.txt && pytest -q || true",
  "customizations": {
    "vscode": {
      "settings": {
        "python.testing.pytestEnabled": true,
        "python.testing.unittestEnabled": false,
        "python.testing.autoTestDiscoverOnSaveEnabled": true
      },
      "extensions": [
        "ms-python.python",
        "ms-python.vscode-pylance"
      ]
    }
  },
  "remoteUser": "vscode"
}
```

## RenderSmokeTest.ps1
```
param(
    [Parameter(Mandatory=$true)][string]$BaseUrl,
    [string]$AdminToken,
    [int]$TimeoutSeconds = 120,
    [int]$IntervalSeconds = 5,
    [switch]$Json
)

Write-Host "Starting smoke test against $BaseUrl" -ForegroundColor Cyan
$deadline = (Get-Date).AddSeconds($TimeoutSeconds)

function Wait-EndpointOk {
    param([string]$Path)
    while((Get-Date) -lt $deadline){
        try {
            $resp = Invoke-WebRequest -Uri ("$BaseUrl$Path") -UseBasicParsing -TimeoutSec 10
            if($resp.StatusCode -eq 200){ return $resp }
        } catch { }
        Write-Host "Waiting for $Path ..." -ForegroundColor DarkGray
        Start-Sleep -Seconds $IntervalSeconds
    }
    throw "Timeout waiting for $Path"
}

# 1. Health
$health = Wait-EndpointOk -Path "/health"
Write-Host "Health OK" -ForegroundColor Green

# 2. Version
$version = Wait-EndpointOk -Path "/version"
Write-Host "Version: $($version.Content)" -ForegroundColor Green

# 3. Admin (best-effort)
try {
    $adminUrl = "/admin"
    if($AdminToken){
        $adminUrl = "$adminUrl?token=$AdminToken"
    }
    $admin = Invoke-WebRequest -Uri ("$BaseUrl$adminUrl") -UseBasicParsing -TimeoutSec 10
    if($admin.StatusCode -eq 200){
        if($admin.Content -match "SECURITY MODE: ENFORCED"){
            Write-Host "Admin reachable (enforced mode)." -ForegroundColor Green
        } elseif($admin.Content -match "SECURITY MODE: OPEN") {
            Write-Host "Admin reachable (open mode)." -ForegroundColor Green
        } else {
            Write-Host "Admin reachable (banner not detected)." -ForegroundColor Yellow
        }
    }
} catch { Write-Warning "Admin check failed: $_" }

try {
    $metrics = Invoke-WebRequest -Uri ("$BaseUrl/metrics") -UseBasicParsing -TimeoutSec 10
    $metricsContent = $metrics.Content
    Write-Host "Metrics fetched." -ForegroundColor Green
} catch { $metricsContent = $null; Write-Warning 'Metrics fetch failed' }

if($Json){
    $obj = [ordered]@{
        baseUrl = $BaseUrl
        health = $health.StatusCode
        versionRaw = $version.Content
        metrics = $metricsContent
        timestamp = (Get-Date).ToUniversalTime().ToString('o')
    }
    $obj | ConvertTo-Json -Depth 4
} else {
    Write-Host "Smoke test complete." -ForegroundColor Cyan
}

```

## scripts\restart_all.ps1
```
<#!
.SYNOPSIS
    Full clean restart of Semptify (local dev / pre-deploy) on Windows PowerShell.
.DESCRIPTION
    Recreates virtual environment (optional), installs dependencies, purges runtime folders (except security allowlist),
    optionally generates an ADMIN_TOKEN & FLASK_SECRET, runs tests, and (optionally) starts the dev or production server.
.PARAMETER ForceVenv
    If set, removes existing .venv and recreates it.
.PARAMETER Prod
    If set, runs run_prod.py with waitress instead of the debug Flask dev server.
.PARAMETER KeepLogs
    If set, preserves existing logs directory contents.
.PARAMETER GenToken
    If set, generates a random ADMIN_TOKEN and exports it for the session.
.PARAMETER Enforced
    If set, sets SECURITY_MODE=enforced (otherwise open).
.PARAMETER SkipTests
    If set, skips running pytest.
.PARAMETER AutoStart
    If set, automatically launches the server after setup.
.EXAMPLE
    ./scripts/restart_all.ps1 -ForceVenv -GenToken -Enforced -AutoStart -Prod
#>
[CmdletBinding()]
param(
    [switch]$ForceVenv,
    [switch]$Prod,
    [switch]$KeepLogs,
    [switch]$GenToken,
    [switch]$Enforced,
    [switch]$SkipTests,
    [switch]$AutoStart
)
$ErrorActionPreference = 'Stop'

function Write-Info($msg){ Write-Host "[*] $msg" -ForegroundColor Cyan }
function Write-Ok($msg){ Write-Host "[+] $msg" -ForegroundColor Green }
function Write-Warn($msg){ Write-Host "[!] $msg" -ForegroundColor Yellow }
function Write-Err($msg){ Write-Host "[x] $msg" -ForegroundColor Red }

$RepoRoot = Split-Path -Parent $MyInvocation.MyCommand.Path | Split-Path -Parent
Set-Location $RepoRoot
Write-Info "Repo root: $RepoRoot"

$venv = Join-Path $RepoRoot '.venv'
if($ForceVenv -and (Test-Path $venv)){
    Write-Info 'Removing existing virtual environment (.venv)'
    Remove-Item -Recurse -Force $venv
}
if(!(Test-Path $venv)){
    Write-Info 'Creating virtual environment (.venv)'
    python -m venv .venv
}
Write-Info 'Activating venv'
. .\.venv\Scripts\Activate.ps1

Write-Info 'Upgrading pip'
python -m pip install --upgrade pip >$null

Write-Info 'Installing requirements'
pip install -r requirements.txt

$RuntimeDirs = @('uploads','logs','copilot_sync','final_notices')
foreach($d in $RuntimeDirs){
    $path = Join-Path $RepoRoot $d
    if(Test-Path $path){
        if($d -eq 'logs' -and $KeepLogs){
            Write-Info "Preserving logs in $d"; continue
        }
        Write-Info "Purging $d/*"
        Get-ChildItem -Force -LiteralPath $path | Remove-Item -Force -Recurse -ErrorAction SilentlyContinue
    } else { New-Item -ItemType Directory -Path $path | Out-Null }
}

# Ensure security dir exists
$secDir = Join-Path $RepoRoot 'security'
if(!(Test-Path $secDir)){ New-Item -ItemType Directory -Path $secDir | Out-Null }

if($GenToken){
    $token = -join ((48..57)+(65..90)+(97..122) | Get-Random -Count 48 | % {[char]$_})
    $env:ADMIN_TOKEN = $token
    Write-Ok "Generated ADMIN_TOKEN (NOT persisted)." 
}
if(-not $env:FLASK_SECRET){
    $env:FLASK_SECRET = [Guid]::NewGuid().ToString('N') + [Guid]::NewGuid().ToString('N')
    Write-Ok 'Generated FLASK_SECRET for session.'
}
$env:SECURITY_MODE = if($Enforced){ 'enforced' } else { 'open' }
Write-Info "SECURITY_MODE=$($env:SECURITY_MODE)"

if(-not $SkipTests){
    Write-Info 'Running tests (pytest -q)'
    try {
        python -m pytest -q
        Write-Ok 'Tests passed'
    } catch {
        Write-Err 'Tests failed'
        throw
    }
}

if($AutoStart){
    if($Prod){
        Write-Info 'Starting production server (waitress)'
        python run_prod.py
    } else {
        Write-Info 'Starting development server (Flask debug)'
        python Semptify.py
    }
} else {
    Write-Ok 'Restart sequence completed. Use -AutoStart to auto-run next time.'
    Write-Host 'Manual start (dev): .\.venv\Scripts\Activate.ps1; python Semptify.py'
    Write-Host 'Manual start (prod): .\.venv\Scripts\Activate.ps1; python run_prod.py'
}

```

## scripts\sbom_vuln_delta.py
```
#!/usr/bin/env python
"""Compare two Trivy JSON reports (old, new) and emit a brief delta summary.

Usage: sbom_vuln_delta.py <old_trivy.json> <new_trivy.json> [--allowlist security/vuln_allowlist.json] [--json-out delta.json]
Exits non-zero (2) if new critical/high count increased (after allowlist suppression).
"""
from __future__ import annotations
import sys, json, argparse, datetime

def load(path: str):
    try:
        with open(path,'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"ERROR: failed reading {path}: {e}", file=sys.stderr)
        sys.exit(1)

def summarize(doc):
    # Trivy SARIF or JSON scanning output forms vary; handle basic JSON (results list)
    critical = high = 0
    if isinstance(doc, dict):
        # syft/trivy action may put results under 'Results'
        results = doc.get('Results') or []
        for r in results:
            vulns = r.get('Vulnerabilities') or []
            for v in vulns:
                sev = (v.get('Severity') or '').upper()
                if sev == 'CRITICAL':
                    critical += 1
                elif sev == 'HIGH':
                    high += 1
    return critical, high

def load_allowlist(path: str):
    try:
        with open(path,'r') as f:
            data = json.load(f)
        entries = {}
        today = datetime.date.today()
        for item in data:
            cve = item.get('cve')
            expires = item.get('expires')
            if not cve:
                continue
            if expires:
                try:
                    exp_date = datetime.date.fromisoformat(expires)
                    if exp_date < today:
                        continue  # expired allowlist entry
                except Exception:
                    pass
            entries[cve] = item
        return entries
    except FileNotFoundError:
        return {}
    except Exception as e:
        print(f"WARN: allowlist load failed: {e}", file=sys.stderr)
        return {}

def extract_vulns(doc):
    vulns = []
    if isinstance(doc, dict):
        results = doc.get('Results') or []
        for r in results:
            for v in r.get('Vulnerabilities') or []:
                vulns.append(v)
    return vulns

def apply_allowlist(vulns, allow):
    kept = []
    suppressed = []
    for v in vulns:
        cve = v.get('VulnerabilityID') or v.get('CVEID')
        if cve and cve in allow:
            suppressed.append(v)
        else:
            kept.append(v)
    return kept, suppressed

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument('old')
    ap.add_argument('new')
    ap.add_argument('--allowlist', default='security/vuln_allowlist.json')
    ap.add_argument('--json-out', default=None)
    args = ap.parse_args()
    old = load(args.old)
    new = load(args.new)
    ocrit, ohigh = summarize(old)
    ncrit, nhigh = summarize(new)
    dcrit = ncrit - ocrit
    dhigh = nhigh - ohigh
    allow = load_allowlist(args.allowlist)
    old_vulns = extract_vulns(old)
    new_vulns = extract_vulns(new)
    new_kept, new_supp = apply_allowlist(new_vulns, allow)
    # Recompute counts after suppression
    ncrit_eff = sum(1 for v in new_kept if (v.get('Severity') or '').upper()=='CRITICAL')
    nhigh_eff = sum(1 for v in new_kept if (v.get('Severity') or '').upper()=='HIGH')
    dcrit_eff = ncrit_eff - ocrit
    dhigh_eff = nhigh_eff - ohigh
    status = 'OK'
    exit_code = 0
    if dcrit_eff > 0 or dhigh_eff > 0:
        status = 'REGRESSION'
        exit_code = 2
    print('TRIVY VULN DELTA\n================')
    print(f'Old: critical={ocrit} high={ohigh}')
    print(f'New(raw): critical={ncrit} high={nhigh}')
    print(f'New(effective): critical={ncrit_eff} high={nhigh_eff} (allowlist suppressed {len(new_supp)})')
    print(f'Delta(effective): critical={dcrit_eff:+} high={dhigh_eff:+}')
    print(f'Status: {status}')
    if args.json_out:
        out = {
            'old': {'critical': ocrit, 'high': ohigh},
            'new_raw': {'critical': ncrit, 'high': nhigh},
            'new_effective': {'critical': ncrit_eff, 'high': nhigh_eff},
            'delta_effective': {'critical': dcrit_eff, 'high': dhigh_eff},
            'suppressed': len(new_supp),
            'status': status
        }
        with open(args.json_out,'w') as f:
            json.dump(out, f, indent=2)
    return exit_code

if __name__ == '__main__':
    sys.exit(main())

```

## scripts\lint.sh
```
#!/usr/bin/env bash
# shellcheck shell=bash
set -euo pipefail

echo "[lint] Python (ruff)"
if command -v ruff >/dev/null 2>&1; then
  ruff check .
else
  echo "[lint] Ruff not installed (skipping)"
fi

echo "[lint] Shell (shellcheck)"
if command -v shellcheck >/dev/null 2>&1; then
  shellcheck scripts/*.sh
else
  echo "[lint] shellcheck not installed (skipping)"
fi

echo "[lint] Dockerfile (hadolint)"
if command -v hadolint >/dev/null 2>&1; then
  hadolint Dockerfile || exit 1
else
  echo "[lint] hadolint not installed (skipping)"
fi

echo "[lint] GitHub Workflows (actionlint)"
if command -v actionlint >/dev/null 2>&1; then
  actionlint || exit 1
else
  echo "[lint] actionlint not installed (skipping)"
fi

echo "[lint] Done"
```

## scripts\wsl_docker_verify.sh
```
#!/usr/bin/env bash
set -euo pipefail

# Lightweight Docker verification for WSL environment.
# Ensures docker CLI works, tests pulling hello-world, and (optional) builds local image.

echo "[INFO] Checking docker availability"
if ! command -v docker >/dev/null 2>&1; then
  echo "[ERROR] docker not found. Re-run wsl_setup.sh with --with-docker or install manually." >&2
  exit 1
fi

echo "[INFO] Docker version: $(docker --version || true)"

echo "[INFO] Running 'docker info' (may require permissions if group not applied yet)"
if ! docker info >/dev/null 2>&1; then
  echo "[WARN] 'docker info' failed. If you just added your user to the docker group, restart WSL (wsl --shutdown)." >&2
else
  echo "[OK] docker info succeeded"
fi

echo "[INFO] Pulling hello-world"
docker pull hello-world:latest >/dev/null
docker run --rm hello-world:latest | head -n 3

if [[ -f Dockerfile ]]; then
  echo "[INFO] Building local Semptify image (quick validation)"
  docker build -t Semptify:local --progress=plain . >/dev/null
  echo "[OK] Image built: Semptify:local"
else
  echo "[SKIP] No Dockerfile in current directory"
fi

echo "[DONE] Docker verification completed."
```

## scripts\wsl_setup.ps1
```
<#!
.SYNOPSIS
  Windows PowerShell wrapper to bootstrap Semptify inside Ubuntu WSL.

.EXAMPLE
  ./scripts/wsl_setup.ps1

.EXAMPLE
  ./scripts/wsl_setup.ps1 -WithDocker -ForceVenv -Dir /mnt/d/Semptify/Semptify

.NOTES
  Pass-through flags map to the bash script: --with-docker, --force-venv, --dir=...
#>
param(
  [switch]$WithDocker,
  [switch]$ForceVenv,
  [string]$Dir
)

Set-StrictMode -Version Latest
$ErrorActionPreference = 'Stop'

function Require-Command($Name){
  if(-not (Get-Command $Name -ErrorAction SilentlyContinue)){
    Write-Error "Required command '$Name' not found. Install WSL components first."
  }
}

Require-Command wsl

# Detect a preferred Ubuntu distro (first matching name containing 'Ubuntu')
$distro = (wsl -l -q | Where-Object { $_ -match 'Ubuntu' } | Select-Object -First 1)
if(-not $distro){
  Write-Error "No Ubuntu WSL distribution found. Install via: wsl --install -d Ubuntu"; exit 1
}

Write-Host "[INFO] Using WSL distro: $distro" -ForegroundColor Cyan

$argsList = @()
if($WithDocker){ $argsList += '--with-docker' }
if($ForceVenv){ $argsList += '--force-venv' }
if($Dir){ $argsList += "--dir=$Dir" }

Write-Host "[INFO] Invoking bootstrap script inside WSL..." -ForegroundColor Cyan
wsl -d $distro -- bash -lc "cd $(wslpath -u (Get-Location)) && bash scripts/wsl_setup.sh $([string]::Join(' ', $argsList))"

Write-Host "[DONE] WSL setup complete." -ForegroundColor Green
```

## scripts\wsl_setup.sh
```
#!/usr/bin/env bash
# shellcheck shell=bash
set -euo pipefail

# Semptify WSL bootstrap script
# Idempotent helper to provision dependencies, virtualenv, and run a smoke test
# Usage:
#   bash scripts/wsl_setup.sh                # basic python environment
#   bash scripts/wsl_setup.sh --with-docker  # additionally install docker engine (WSL2 Ubuntu)
#   bash scripts/wsl_setup.sh --force-venv   # recreate virtualenv even if it exists
#
# Safe to re-run; will skip steps that are already satisfied.

REPO_GIT="https://github.com/Bradleycrowe/Semptify.git"
PROJECT_NAME="Semptify"
DEFAULT_WIN_PATH="/mnt/d/Semptify/${PROJECT_NAME}"  # Adjust if your code is elsewhere
TARGET_DIR=""
WITH_DOCKER=0
FORCE_VENV=0

# Robust argument parsing (avoids shifting inside a for loop; passes shellcheck)
while [ $# -gt 0 ]; do
	case "$1" in
		--with-docker) WITH_DOCKER=1; shift ;;
		--force-venv) FORCE_VENV=1; shift ;;
		--dir=*) TARGET_DIR="${1#*=}"; shift ;;
		-h|--help)
			grep '^#' "$0" | sed 's/^# \{0,1\}//'
			exit 0 ;;
		*)
			echo "[WARN] Unknown argument: $1" >&2; shift ;;
	esac
done

echo "[INFO] Starting WSL setup for ${PROJECT_NAME}"

# -------- Detect WSL / distro --------
if ! grep -qi 'microsoft' /proc/version; then
	echo "[WARN] This does not look like WSL. Continuing anyway." >&2
fi

if ! command -v apt >/dev/null 2>&1; then
	echo "[ERROR] This script expects an apt-based distro (Ubuntu/Debian)." >&2
	exit 1
fi

# -------- Choose target directory --------
if [ -z "$TARGET_DIR" ]; then
  if [ -d "$DEFAULT_WIN_PATH/.git" ]; then
    TARGET_DIR="$DEFAULT_WIN_PATH"
  else
    TARGET_DIR="$HOME/${PROJECT_NAME}"
  fi
fi
echo "[INFO] Target directory: $TARGET_DIR"

# -------- Packages --------
echo "[INFO] Updating apt metadata (sudo required)"
sudo apt update -y
echo "[INFO] Installing base packages"
sudo apt install -y --no-install-recommends \
	python3 python3-venv python3-pip git ca-certificates curl build-essential

if [ "$WITH_DOCKER" -eq 1 ]; then
	echo "[INFO] Installing Docker (engine + CLI)"
	if ! command -v docker >/dev/null 2>&1; then
		# Reference: https://docs.docker.com/engine/install/ubuntu/
		sudo apt install -y apt-transport-https gnupg lsb-release
		curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker.gpg
		echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
		sudo apt update -y
		sudo apt install -y docker-ce docker-ce-cli containerd.io
		sudo usermod -aG docker "$USER" || true
		echo "[INFO] Docker installed. You may need to log out/in for group changes to apply."
	else
		echo "[INFO] Docker already present; skipping."
	fi
fi

# -------- Clone or reuse repo --------
if [ -d "$TARGET_DIR/.git" ]; then
	echo "[INFO] Existing git repo detected. Pulling latest main."
	(cd "$TARGET_DIR" && git fetch --all --prune && git checkout main && git pull --ff-only) || echo "[WARN] Git pull failed; continuing."
else
	echo "[INFO] Cloning repository into $TARGET_DIR"
	mkdir -p "$(dirname "$TARGET_DIR")"
	git clone "$REPO_GIT" "$TARGET_DIR"
fi

cd "$TARGET_DIR"

# -------- Python virtual environment --------
if [ -d .venv ] && [ "$FORCE_VENV" -eq 1 ]; then
	echo "[INFO] --force-venv specified; removing existing .venv"
	rm -rf .venv
fi

if [ ! -d .venv ]; then
	echo "[INFO] Creating virtualenv (.venv)"
	python3 -m venv .venv
fi

echo "[INFO] Upgrading pip & installing requirements"
# shellcheck disable=SC1091  # virtualenv activation script is generated at runtime
source .venv/bin/activate
python -m pip install --upgrade pip
pip install -r requirements.txt

# -------- Smoke tests --------
if command -v pytest >/dev/null 2>&1; then
	echo "[INFO] Running quick test subset (index + health)"
	pytest -q tests/test_app.py::test_index tests/test_admin_open_mode.py::test_admin_open_mode_access || echo "[WARN] Some tests failed (non-blocking)."
else
	echo "[INFO] pytest not available; skipping tests"
fi

# -------- Run guidance --------
cat <<'EOF'

[DONE] Semptify environment prepared.

To run the development server inside WSL now:
	source .venv/bin/activate
	python Semptify.py

Then visit: http://127.0.0.1:5000

Production-style (waitress):
	source .venv/bin/activate
	python run_prod.py

Environment variables (examples):
	export SECURITY_MODE=open
	export ADMIN_TOKEN=changeme
	export FLASK_SECRET="$(python - <<'PY'
import secrets; print(secrets.token_hex(32))
PY
)"

If you enabled Docker and just added your user to the docker group, restart your WSL session for group membership to refresh.
EOF

echo "[INFO] Script complete"

```

## scripts\sbom_diff.py
```
#!/usr/bin/env python
import sys, json, collections

if len(sys.argv) != 3:
    print("Usage: sbom_diff.py <old.json> <new.json>", file=sys.stderr)
    sys.exit(1)

with open(sys.argv[1],'r') as f: old = json.load(f)
with open(sys.argv[2],'r') as f: new = json.load(f)

# Try to support Syft & CycloneDX minimal shapes (very loose heuristic)

def extract_components(doc):
    comps = []
    if isinstance(doc, dict):
        if 'components' in doc and isinstance(doc['components'], list):
            for c in doc['components']:
                name = c.get('name') or c.get('componentName') or c.get('id')
                version = c.get('version') or c.get('componentVersion')
                purl = c.get('purl')
                if name:
                    comps.append((name, version, purl))
        elif 'artifacts' in doc and isinstance(doc['artifacts'], list):  # syft JSON
            for a in doc['artifacts']:
                name = a.get('name')
                version = a.get('version')
                purl = None
                if name:
                    comps.append((name, version, purl))
    return comps

old_set = set(extract_components(old))
new_set = set(extract_components(new))
added = sorted(new_set - old_set)
removed = sorted(old_set - new_set)

print("SBOM DIFF SUMMARY\n=================")
print(f"Old file: {sys.argv[1]}")
print(f"New file: {sys.argv[2]}\n")
print(f"Added components: {len(added)}")
for a in added[:50]:
    print(" +", a[0], a[1] or '')
print(f"\nRemoved components: {len(removed)}")
for r in removed[:50]:
    print(" -", r[0], r[1] or '')

if len(added) > 50 or len(removed) > 50:
    print("\n(Results truncated)")

```

## scripts\restart_all.sh
```
#!/usr/bin/env bash
set -euo pipefail
# Full clean restart helper for Semptify (Linux/WSL)
# Flags:
#   --force-venv      Recreate venv
#   --prod            Run run_prod.py after setup
#   --keep-logs       Keep existing logs directory contents
#   --gen-token       Generate random ADMIN_TOKEN for session
#   --enforced        Set SECURITY_MODE=enforced (default open)
#   --skip-tests      Skip pytest
#   --auto-start      Start server automatically
# Usage: ./scripts/restart_all.sh --force-venv --gen-token --enforced --auto-start --prod

force_venv=0
prod=0
keep_logs=0
gen_token=0
enforced=0
skip_tests=0
auto_start=0

while [[ $# -gt 0 ]]; do
  case "$1" in
    --force-venv) force_venv=1 ; shift ;;
    --prod) prod=1 ; shift ;;
    --keep-logs) keep_logs=1 ; shift ;;
    --gen-token) gen_token=1 ; shift ;;
    --enforced) enforced=1 ; shift ;;
    --skip-tests) skip_tests=1 ; shift ;;
    --auto-start) auto_start=1 ; shift ;;
    -h|--help)
      grep '^#' "$0" | sed 's/^# \{0,1\}//'; exit 0 ;;
    *) echo "Unknown arg: $1" >&2; exit 2 ;;
  esac
done

info(){ echo -e "\e[36m[*]\e[0m $*"; }
ok(){ echo -e "\e[32m[+]\e[0m $*"; }
warn(){ echo -e "\e[33m[!]\e[0m $*"; }
err(){ echo -e "\e[31m[x]\e[0m $*"; }

repo_root="$(cd "$(dirname "$0")/.." && pwd)"
cd "$repo_root"
info "Repo root: $repo_root"

if [[ $force_venv -eq 1 && -d .venv ]]; then
  info "Removing existing venv"
  rm -rf .venv
fi
if [[ ! -d .venv ]]; then
  info "Creating venv"
  python -m venv .venv
fi
# shellcheck disable=SC1091
source .venv/bin/activate
info "Upgrading pip"
python -m pip install --upgrade pip >/dev/null
info "Installing requirements"
pip install -r requirements.txt

runtime_dirs=(uploads logs copilot_sync final_notices)
for d in "${runtime_dirs[@]}"; do
  mkdir -p "$d"
  if [[ $d == logs && $keep_logs -eq 1 ]]; then
    info "Keeping existing logs"
    continue
  fi
  info "Purging $d/*"
  find "$d" -mindepth 1 -maxdepth 1 -exec rm -rf {} + || true
done

mkdir -p security
if [[ $gen_token -eq 1 ]]; then
  export ADMIN_TOKEN="$(tr -dc 'A-Za-z0-9' </dev/urandom | head -c 48)"
  ok "Generated ADMIN_TOKEN (not persisted)"
fi
if [[ -z "${FLASK_SECRET:-}" ]]; then
  export FLASK_SECRET="$(python - <<'PY'
import secrets;print(secrets.token_hex(64))
PY
)"
  ok "Generated FLASK_SECRET"
fi
export SECURITY_MODE=$([[ $enforced -eq 1 ]] && echo enforced || echo open)
info "SECURITY_MODE=$SECURITY_MODE"

if [[ $skip_tests -ne 1 ]]; then
  info "Running tests"
  if python -m pytest -q; then
    ok "Tests passed"
  else
    err "Tests failed"; exit 3
  fi
else
  warn "Skipping tests"
fi

if [[ $auto_start -eq 1 ]]; then
  if [[ $prod -eq 1 ]]; then
    info "Starting production server (waitress)"
    exec python run_prod.py
  else
    info "Starting development server (Flask debug)"
    exec python Semptify.py
  fi
else
  ok "Restart sequence complete. Use --auto-start to run automatically."
  echo "Manual start (dev): source .venv/bin/activate; python Semptify.py"
  echo "Manual start (prod): source .venv/bin/activate; python run_prod.py"
fi

```

## static\js\service-worker.js
```
const CACHE_NAME = 'semptify-cache-v2';
const CORE_ASSETS = [
  '/',
  '/offline',
  '/static/css/app.css',
  '/static/manifest.webmanifest',
  '/version',
  '/health'
];
self.addEventListener('install', (e) => {
  e.waitUntil(
    caches.open(CACHE_NAME).then(cache => cache.addAll(CORE_ASSETS))
  );
});
self.addEventListener('activate', (e) => {
  e.waitUntil(
    caches.keys().then(keys => Promise.all(keys.filter(k => k !== CACHE_NAME).map(k => caches.delete(k))))
  );
});
self.addEventListener('fetch', (e) => {
  const req = e.request;
  if (req.method !== 'GET') return;
  const url = new URL(req.url);
  // HTML navigation fallback offline
  if (req.mode === 'navigate') {
    e.respondWith(
      fetch(req).catch(() => caches.match('/offline'))
    );
    return;
  }
  e.respondWith(
    caches.match(req).then(cached => {
      const fetchPromise = fetch(req).then(networkResp => {
        if(networkResp && networkResp.status === 200){
          const cloned = networkResp.clone();
          caches.open(CACHE_NAME).then(cache => cache.put(req, cloned));
        }
        return networkResp;
      }).catch(() => cached);
      return cached || fetchPromise;
    })
  );
});

```

## static\css\app.css
```
/* Basic responsive layout */
:root { --bg:#f6f9fc; --card:#ffffff; --border:#d9e2ec; --primary:#1d3557; --accent:#457b9d; --accent-alt:#e76f51; --radius:10px; --text:#222; --muted:#5a6b7b; font-family: system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,sans-serif; }
/* Dark theme variables */
[data-theme="dark"] { --bg:#0f1720; --card:#15232f; --border:#1e3545; --text:#f1f5f9; --muted:#93a4b4; --primary:#25496b; --accent:#4ea3d9; --accent-alt:#fb8500; }
body { margin:0; background:var(--bg); color:var(--text); transition:background .3s,color .3s; }
.app-header { display:flex; flex-wrap:wrap; align-items:center; justify-content:space-between; background:var(--primary); color:#fff; padding:0.75rem 1rem; }
.app-header h1 { margin:0; font-size:1.25rem; }
.app-header nav a { color:#fff; text-decoration:none; margin-right:1rem; font-size:0.9rem; opacity:.9; }
.app-header nav a:hover { opacity:1; }
.app-header nav a:last-child { margin-right:0; }
.content { max-width:1200px; margin:1.5rem auto 4.5rem; padding:0 1.25rem; display:grid; gap:1.25rem; grid-template-columns:repeat(auto-fit,minmax(260px,1fr)); }
.card { background:var(--card); border:1px solid var(--border); border-radius:var(--radius); padding:1rem; box-shadow:0 2px 4px rgba(0,0,0,0.04); }
.card h2 { margin-top:0; font-size:1.1rem; }
button, .btn { background:var(--accent); border:none; color:#fff; padding:0.6rem 1rem; border-radius:6px; cursor:pointer; font-weight:500; font-size:.9rem; display:inline-flex; align-items:center; gap:.4rem; }
button.secondary, .btn.secondary { background:var(--accent-alt); }
button:disabled { opacity:0.55; cursor:not-allowed; }
button:hover:not(:disabled) { filter:brightness(1.05); }
#installBtn { margin-top:.5rem; }
.badge { display:inline-block; background:var(--accent); color:#fff; padding:0.25rem .55rem; border-radius:999px; font-size:.65rem; letter-spacing:.5px; text-transform:uppercase; }
.status-grid { display:grid; gap:.5rem; }
.hero { grid-column:1/-1; display:grid; gap:1rem; background:linear-gradient(135deg,var(--primary),var(--accent)); color:#fff; padding:1.5rem 1.25rem; border-radius:var(--radius); box-shadow:0 4px 20px -4px rgba(0,0,0,.25); }
.hero h1 { margin:.2rem 0 0; font-size:1.85rem; letter-spacing:.5px; }
.hero p { margin:.35rem 0 0; max-width:720px; line-height:1.4; }
.theme-toggle { background:rgba(255,255,255,.15); border:1px solid rgba(255,255,255,.35); padding:.4rem .75rem; border-radius:999px; cursor:pointer; font-size:.7rem; text-transform:uppercase; letter-spacing:1px; }
.theme-toggle:hover { background:rgba(255,255,255,.25); }
.muted { color:var(--muted); }
.inline-kv { display:flex; flex-wrap:wrap; gap:.75rem; font-size:.75rem; }
.inline-kv span { background:var(--card); color:var(--text); padding:.25rem .55rem; border-radius:6px; border:1px solid var(--border); }
.app-footer { position:fixed; bottom:0; left:0; right:0; background:#fff; border-top:1px solid var(--border); padding:0.5rem 1rem; font-size:0.75rem; text-align:center; }
[data-theme="dark"] .app-footer { background:#15232f; }
@media (max-width:600px){ .content { grid-template-columns:1fr; } .app-header nav a { margin-right:0.6rem; } }

```

## static\css\admin.css
```
.banner { padding:8px; font-weight:bold; }
.banner-open { background:#ffd966; color:#222; }
.banner-enforced { background:#d9ead3; color:#222; }
.rotate-form { margin-top:1rem; }

```

## AllInOne-Push.ps1
```
<#
AllInOne-Push.ps1
Purpose: One-stop local pipeline: lint -> test -> build (with metadata) -> container smoke test -> SBOM (Syft) -> Trivy scan -> optional tag -> push.

Usage examples:
  ./AllInOne-Push.ps1 -Message "feat: add x" -TagAuto
  ./AllInOne-Push.ps1 -Message "chore: maintenance" -FailOnVuln
  ./AllInOne-Push.ps1 -SkipSBOM -SkipTrivy

Parameters:
  -Message        Commit message (default: chore: all-in-one autopush)
  -Tag            Explicit tag name (e.g. v1.2.3). Skips auto strategy.
  -TagAuto        If set and -Tag not supplied, creates timestamp tag vYYYYMMDDHHMMSS
  -FailOnVuln     Exit non-zero if Trivy finds HIGH/CRITICAL vulns
  -SkipSBOM       Skip SBOM generation
  -SkipTrivy      Skip vulnerability scan
  -SkipDocker     Skip docker build + smoke
  -SkipVenv       Skip virtual environment setup
  -Push           Actually push branch + tag (otherwise dry-run commit only)
  -DispatchCI     After push, attempt to dispatch ci.yml workflow via GitHub API (needs GITHUB_TOKEN env)

Outputs:
  sbom/sbom.json              (if SBOM not skipped)
  security/trivy-report.sarif (if Trivy not skipped; directory created if absent)

Prerequisites:
  - Docker installed (for Syft/Trivy container invocations)
  - Git configured
  - Python available
  - Optional env: GITHUB_TOKEN for workflow dispatch / tagging via API not required here (git tag local)
#>
param(
  [string]$Message = "chore: all-in-one autopush",
  [string]$Tag = "",
  [switch]$TagAuto,
  [switch]$FailOnVuln,
  [switch]$SkipSBOM,
  [switch]$SkipTrivy,
  [switch]$SkipDocker,
  [switch]$SkipVenv,
  [switch]$Push,
  [switch]$DispatchCI
)

$ErrorActionPreference = 'Stop'
$repo = Split-Path -Parent $MyInvocation.MyCommand.Path
Set-Location $repo

# --- Helpers ---
function Info($m){ Write-Host "[AIO] $m" -ForegroundColor Cyan }
function Warn($m){ Write-Host "[AIO] $m" -ForegroundColor Yellow }
function Err($m){ Write-Host "[AIO] $m" -ForegroundColor Red }
function Run($cmd){ Info $cmd; Invoke-Expression $cmd }

# --- Venv setup ---
$venv = Join-Path $repo '.venv'
if(-not $SkipVenv){
  if(-not (Test-Path (Join-Path $venv 'pyvenv.cfg'))){
    Info "(Re)creating venv"
    python -m venv .venv
  }
  . .\.venv\Scripts\Activate.ps1
  pip install --upgrade pip >$null
  pip install -q -r requirements.txt
  pip install -q ruff pytest || throw 'Dependency install failed'
}else{ Warn 'Skipping venv phase' }

# --- Lint ---
Info 'Linting with ruff'
try { ruff check . } catch { Err 'Lint failed'; throw }

# --- Tests ---
Info 'Running tests'
python -m pytest -q

$gitSha = (git rev-parse --short HEAD).Trim()
$buildTime = (Get-Date -Format o)

# --- Docker build & smoke ---
$imageName = 'Semptify:local'
if(-not $SkipDocker){
  Info "Building image $imageName (sha=$gitSha)"
  docker build --build-arg GIT_SHA=$gitSha --build-arg BUILD_TIME=$buildTime -t $imageName .
  Info 'Running container smoke test'
  $cid = docker run -d -p 127.0.0.1:8090:8080 --name semptify_aio $imageName
  Start-Sleep -Seconds 6
  try {
    $resp = Invoke-WebRequest -Uri 'http://127.0.0.1:8090/health' -UseBasicParsing -TimeoutSec 5
    if($resp.StatusCode -ne 200){ Warn "Health returned $($resp.StatusCode)" }
  } catch { Warn "Health check failed: $($_.Exception.Message)" }
  docker stop semptify_aio *> $null
  docker rm semptify_aio *> $null
}else{ Warn 'Skipping docker build & smoke' }

New-Item -ItemType Directory -Force -Path sbom | Out-Null
New-Item -ItemType Directory -Force -Path security | Out-Null

# --- SBOM ---
$sbomFile = 'sbom/sbom.json'
if(-not $SkipSBOM){
  if($SkipDocker){ Warn 'SBOM requires built image; building lightweight image'; docker build -t $imageName . }
  Info 'Generating SBOM (Syft container)'
  docker run --rm anchore/syft:latest $imageName -o json > $sbomFile
  if(-not (Test-Path $sbomFile) -or (Get-Item $sbomFile).Length -lt 50){ Err 'SBOM generation failed'; throw }
}else{ Warn 'Skipping SBOM generation' }

# --- Trivy scan ---
$trivySarif = 'security/trivy-report.sarif'
$vulnExit = 0
if(-not $SkipTrivy){
  if($SkipDocker){ Warn 'Trivy requires image; building image'; docker build -t $imageName . }
  Info 'Running Trivy vulnerability scan'
  docker run --rm -v /var/run/docker.sock:/var/run/docker.sock aquasec/trivy:latest image --format sarif --output $trivySarif --severity HIGH,CRITICAL $imageName || ($vulnExit=$LASTEXITCODE)
  if(-not (Test-Path $trivySarif)){ Err 'Trivy SARIF not produced'; throw }
  if($FailOnVuln -and $vulnExit -ne 0){ Err 'Failing due to vulnerabilities'; throw 'Vulnerabilities found' }
}else{ Warn 'Skipping Trivy scan' }

# --- Git commit + optional tag ---
Info 'Staging changes (excluding bulky runtime)'
# Avoid adding uploads/logs/security
Get-ChildItem -Force | Out-Null

git add .dockerignore Dockerfile *.py templates/ sbom/ security/trivy-report.sarif 2>$null
if(Test-Path $sbomFile){ git add $sbomFile }
try { git commit -m $Message } catch { Warn 'Nothing to commit or commit failed (maybe no changes)' }

if([string]::IsNullOrWhiteSpace($Tag)){
  if($TagAuto){ $Tag = 'v' + (Get-Date -Format 'yyyyMMddHHmmss') }
}
if(-not [string]::IsNullOrWhiteSpace($Tag)){
  if(-not (git tag -l $Tag)){ git tag $Tag; Info "Created tag $Tag" } else { Warn "Tag $Tag already exists" }
}

if($Push){
  Info 'Pushing branch'
  git push origin main
  if(-not [string]::IsNullOrWhiteSpace($Tag)){ git push origin $Tag }
} else {
  Warn 'Push skipped (use -Push to enable)'
}

# --- Optional workflow dispatch ---
if($DispatchCI -and $Push){
  if($env:GITHUB_TOKEN){
    $owner = $env:GITHUB_OWNER; if(-not $owner){ $owner='Bradleycrowe' }
    $repoName = $env:GITHUB_REPO; if(-not $repoName){ $repoName='Semptify' }
    $body = '{"ref":"main"}'
    $url = "https://api.github.com/repos/$owner/$repoName/actions/workflows/ci.yml/dispatches"
    Info 'Dispatching CI workflow'
    try {
      Invoke-RestMethod -Method Post -Uri $url -Headers @{Authorization="token $($env:GITHUB_TOKEN)"; Accept='application/vnd.github+json'} -Body $body
    } catch { Warn "Workflow dispatch failed: $($_.Exception.Message)" }
  } else { Warn 'GITHUB_TOKEN not set; cannot dispatch workflow' }
}

Write-Host ''
Write-Host '========== All-In-One Summary ==========' -ForegroundColor Green
Write-Host "Commit Message : $Message"
Write-Host "Tag            : $([string]::IsNullOrWhiteSpace($Tag) ? 'none' : $Tag)"
Write-Host "Pushed         : $Push"
Write-Host "SBOM           : $([bool](-not $SkipSBOM)) -> $sbomFile"
Write-Host "Trivy Scan     : $([bool](-not $SkipTrivy)) -> $trivySarif"
Write-Host "FailOnVuln     : $FailOnVuln (exit=$vulnExit)"
Write-Host "Docker Built   : $([bool](-not $SkipDocker))"
Write-Host "Git SHA        : $gitSha"
Write-Host '=========================================' -ForegroundColor Green

```

## render.yaml
```
services:
  - type: web
    name: Semptify
    env: python
    plan: free
    region: oregon
    buildCommand: pip install -r requirements.txt
    startCommand: python run_prod.py
    envVars:
      - key: SEMPTIFY_PORT
        value: 8080
      - key: ADMIN_TOKEN
        sync: false
      - key: SECURITY_MODE
        value: open
    autoDeploy: true
    healthCheckPath: /health
    disk:
      name: semptify-data
      mountPath: /app/uploads
      sizeGB: 1

```

## PushAndDeploy-Semptify.ps1
```
# PushAndDeploy-Semptify.ps1 — All-in-one commit, push, build, and deploy for Semptify

$repoPath = "D:\Semptify\Semptify"
$liveURL = "https://Semptify.onrender.com"
$renderDashboard = "https://dashboard.render.com"

Set-Location $repoPath

Write-Host "🔄 Staging all changes..."
git add .

Write-Host "📝 Committing changes..."
git commit -m "chore: all-in-one deploy — update, build, push, and verify Semptify"
if ($LASTEXITCODE -ne 0) {
    Write-Host "⚠️ Git commit failed or nothing to commit."
}

Write-Host "🚀 Pushing to GitHub..."
git push origin main
if ($LASTEXITCODE -eq 0) {
    Write-Host "🐳 Building Docker container locally for verification..."
    docker-compose down
    docker-compose up --build -d

    Write-Host "🌐 Opening Render dashboard..."
    Start-Process $renderDashboard

    Write-Host "🌍 Opening live app in browser..."
    Start-Sleep -Seconds 5
    Start-Process $liveURL

    Write-Host "`n✅ Semptify pushed, built, and deployed."
    Write-Host "🌐 Live at: $liveURL"
    Write-Host "🧠 Backend: Semptify.py wired and running"
    Write-Host "🔘 Buttons: Upload, Logs, Sync, Generate, Security — all active"
} else {
    Write-Host "❌ Git push failed. Check your network or remote repo status."
}
```

## SemptifyCleanupGUI.py
```
from flask import Flask, render_template_string, request, redirect
import os
from datetime import datetime

app = Flask(__name__)

# Ensure runtime folders exist
for folder in ['uploads', 'logs', 'copilot_sync', 'final_notices', 'security']:
    os.makedirs(folder, exist_ok=True)

# HTML dashboard with all buttons
dashboard_html = """
<!DOCTYPE html>
<html>
<head><title>Semptify</title></head>
<body>
  <h1>Semptify Control Panel</h1>
  <form action="/upload" method="post"><button>Upload Evidence</button></form>
  <a href="/logs"><button>View Logs</button></a>
  <form action="/sync" method="post"><button>Copilot Sync Now</button></form>
  <form action="/generate" method="post"><button>Generate Notice</button></form>
  <a href="/security"><button>Security Check</button></a>
</body>
</html>
"""

@app.route('/')
def home():
    return render_template_string(dashboard_html)

@app.route('/upload', methods=['POST'])
def upload():
    with open('uploads/upload_log.txt', 'a') as f:
        f.write(f"Evidence uploaded at {datetime.now()}\n")
    return redirect('/')

@app.route('/logs')
def logs():
    entries = []
    for fname in os.listdir('logs'):
        with open(f'logs/{fname}', 'r') as f:
            entries.append(f.read())
    return "<br>".join(entries) or "No logs yet."

@app.route('/sync', methods=['POST'])
def sync():
    with open('copilot_sync/sync_log.txt', 'a') as f:
        f.write(f"Copilot synced at {datetime.now()}\n")
    return redirect('/')

@app.route('/generate', methods=['POST'])
def generate():
    with open('final_notices/notice.txt', 'w') as f:
        f.write("Final notice generated.\n")
    return redirect('/')

@app.route('/security')
def security():
    return "Security check passed."

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)

```

## Push-Semptify.ps1
```
# Push-Semptify.ps1 — Push all modules and prep for Render deployment

# Set canonical repo path
$repoPath = "D:\Semptify\Semptify"
$renderURL = "https://dashboard.render.com"
$liveURL = "https://Semptify.onrender.com"

# Step 1: Navigate to repo
Set-Location $repoPath

# Step 2: Git push all changes
git add .
git commit -m "v0.1.1: All modules wired — full justice-grade GUI"
git push origin main

# Step 3: Launch Render dashboard for manual deploy
Start-Process $renderURL

# Step 4: Display Render setup instructions
Write-Host "`n✅ Git pushed. Now deploy manually on Render:"
Write-Host "🔧 Clear Build Cache"
Write-Host "🔧 Environment: Python 3.11+"
Write-Host "🔧 Build Command: pip install -r requirements.txt"
Write-Host "🔧 Start Command: python SemptifyCleanupGUI.py"
Write-Host "🔧 Port: 5000"
Write-Host "`n🌐 Live URL: $liveURL"

# Step 5: Open live app (if already deployed)
Start-Sleep -Seconds 5
Start-Process $liveURL

```

## Deploy-Semptify.ps1
```
# Deploy-Semptify.ps1 — Justice-grade deployment from D:\Semptify\Semptify

# Set canonical repo path
$repoPath = "D:\Semptify\Semptify"
$renderURL = "https://dashboard.render.com"
$liveURL = "https://semptify.onrender.com"

# Step 1: Navigate to repo
Set-Location $repoPath

# Step 2: Git push
git add .
git commit -m "v0.1-stable: ready for Render"
git push origin main

# Step 3: Launch Render dashboard
Start-Process $renderURL

# Step 4: Display Render setup instructions
Write-Host "`n✅ Git pushed. Now configure Render:"
Write-Host "🔧 Environment: Python 3.11+"
Write-Host "🔧 Build Command: pip install -r requirements.txt"
Write-Host "🔧 Start Command: python SemptifyCleanupGUI.py"
Write-Host "🔧 Port: 5000"
Write-Host "`n🌐 Suggested live URL: $liveURL"

# Step 5: Open live app (if already deployed)
Start-Sleep -Seconds 5
Start-Process $liveURL

```

## requirements.txt
```
Flask>=3.1.2
waitress>=2.1.2
requests>=2.31.0
pytest>=8.2.0

```

## Semptify.py
```
from flask import Flask, render_template, request, redirect, send_file, jsonify, abort, session
import os
from datetime import datetime, timezone
import json
import requests
import time
import threading
import hashlib
import uuid
from collections import deque, defaultdict
from typing import Optional, Callable

# -----------------------------
# Rate limiting (simple sliding window) & config
# -----------------------------
RATE_LIMIT_WINDOW_SECONDS = int(os.environ.get('ADMIN_RATE_WINDOW', '60'))
RATE_LIMIT_MAX_REQUESTS = int(os.environ.get('ADMIN_RATE_MAX', '60'))  # per window per IP
RATE_LIMIT_STATUS = int(os.environ.get('ADMIN_RATE_STATUS', '429'))  # HTTP status for rate limiting
RATE_LIMIT_RETRY_AFTER = int(os.environ.get('ADMIN_RATE_RETRY_AFTER', os.environ.get('ADMIN_RATE_WINDOW', '60')))  # seconds clients should wait before retry
_RATE_HISTORY = defaultdict(lambda: deque())  # key -> deque[timestamps]
_rate_lock = threading.Lock()

def _rate_limit(key: str) -> bool:
    """Return True if allowed, False if over limit."""
    if RATE_LIMIT_MAX_REQUESTS <= 0:
        return True
    now = time.time()
    window_start = now - RATE_LIMIT_WINDOW_SECONDS
    with _rate_lock:
        dq = _RATE_HISTORY[key]
        # Purge old
        while dq and dq[0] < window_start:
            dq.popleft()
        if len(dq) >= RATE_LIMIT_MAX_REQUESTS:
            return False
        dq.append(now)
    return True

# In-memory metrics (simple counters; reset on restart)
METRICS = {
    'requests_total': 0,
    'admin_requests_total': 0,
    'admin_actions_total': 0,
    'errors_total': 0,
    'releases_total': 0,
    'rate_limited_total': 0,
    'breakglass_used_total': 0,
    'token_rotations_total': 0,
}
_metrics_lock = threading.Lock()
_START_TIME = time.time()

def _inc(metric: str, amt: int = 1):
    with _metrics_lock:
        METRICS[metric] = METRICS.get(metric, 0) + amt

def _metrics_text() -> str:
    # Expose simple Prometheus style with HELP/TYPE
    help_map = {
        'requests_total': 'Total HTTP requests (all endpoints)',
        'admin_requests_total': 'Total authenticated admin requests',
        'admin_actions_total': 'Total mutating admin actions performed',
        'errors_total': 'Total error responses (admin + general)',
        'releases_total': 'Total release tags created via UI',
        'rate_limited_total': 'Total admin requests blocked by rate limiting',
        'breakglass_used_total': 'Total successful break-glass authentications',
        'token_rotations_total': 'Total admin token rotations executed'
    }
    lines = []
    for k, v in METRICS.items():
        if k in help_map:
            lines.append(f"# HELP {k} {help_map[k]}")
            lines.append(f"# TYPE {k} counter")
        lines.append(f"{k} {v}")
    # Dynamic uptime gauge (not stored in METRICS since it changes continuously)
    uptime = int(time.time() - _START_TIME)
    lines.append("# HELP uptime_seconds Application uptime in seconds")
    lines.append("# TYPE uptime_seconds gauge")
    lines.append(f"uptime_seconds {uptime}")
    return "\n".join(lines) + "\n"

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# Make template/static paths explicit so deployment environments with different CWDs still resolve correctly
app = Flask(
    __name__,
    template_folder=os.path.join(BASE_DIR, 'templates'),
    static_folder=os.path.join(BASE_DIR, 'static')
)
# Secret key for session/CSRF (set FLASK_SECRET in production)
app.secret_key = os.environ.get('FLASK_SECRET', os.urandom(32))

# Required folders
folders = ["uploads", "logs", "copilot_sync", "final_notices", "security"]

# Create folders if missing
for folder in folders:
    if not os.path.exists(folder):
        os.makedirs(folder)

def _bootstrap_tokens_if_needed():
    """If in enforced mode and tokens file missing but ADMIN_TOKEN env provided, create a single-entry tokens file.
    This eases first-time hardened deployments without manually crafting JSON. Idempotent: does nothing if file exists.
    """
    if _current_security_mode() != 'enforced':
        return
    path = os.path.join('security','admin_tokens.json')
    if os.path.exists(path):
        return
    legacy = os.environ.get('ADMIN_TOKEN')
    if not legacy:
        return
    entry = [{ 'id': 'legacy-bootstrap', 'hash': _hash_token(legacy), 'enabled': True }]
    try:
        with open(path,'w') as f:
            json.dump(entry, f, indent=2)
        _append_log('Bootstrapped admin_tokens.json from ADMIN_TOKEN env (legacy-bootstrap)')
        _event_log('tokens_bootstrap_created')
    except Exception as e:  # pragma: no cover
        _append_log(f'tokens_bootstrap_failed {e}')

def _utc_now():
    """Return an aware UTC datetime."""
    return datetime.now(timezone.utc)

def _utc_now_iso():
    """Return RFC3339-ish UTC timestamp with trailing Z."""
    return _utc_now().isoformat().replace('+00:00', 'Z')

def _rotate_if_needed(path: str):
    max_bytes = int(os.environ.get('LOG_MAX_BYTES', '1048576'))  # 1 MB default
    if not os.path.exists(path):
        return
    try:
        size = os.path.getsize(path)
        if size < max_bytes:
            return
        ts = _utc_now().strftime('%Y%m%d%H%M%S')
        rotated = f"{path}.{ts}"
        os.rename(path, rotated)
    except Exception:
        # Silent failure; rotation is best-effort
        pass

def _append_log(line: str):
    log_path_local = os.path.join("logs", "init.log")
    _rotate_if_needed(log_path_local)
    timestamp_local = _utc_now().strftime("%Y-%m-%d %H:%M:%S")
    with open(log_path_local, "a") as f:
        f.write(f"[{timestamp_local}] {line}\n")

def _event_log(event: str, **fields):
    """Structured JSON event log (append-only)."""
    log_path = os.path.join('logs', 'events.log')
    _rotate_if_needed(log_path)
    payload = {
        'ts': _utc_now_iso(),
        'event': event,
        **fields
    }
    try:
        with open(log_path, 'a') as f:
            f.write(json.dumps(payload) + "\n")
    except Exception as e:
        _append_log(f"event_log_error {e}")

# -----------------------------
# Simple .env loader (no external dependency) executed *before* using env vars in prod runner
# -----------------------------
def load_dotenv(path: str = '.env') -> None:
    if not os.path.exists(path):
        return
    try:
        with open(path, 'r') as f:
            for raw in f:
                line = raw.strip()
                if not line or line.startswith('#'):
                    continue
                if '=' not in line:
                    continue
                k, v = line.split('=', 1)
                k = k.strip()
                v = v.strip().strip('"').strip("'")
                os.environ.setdefault(k, v)  # do not override existing explicit env
    except Exception as e:  # pragma: no cover
        _append_log(f"dotenv_load_error {e}")

# Attempt to load .env from project root (idempotent)
load_dotenv(os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env'))
_bootstrap_tokens_if_needed()

def _current_security_mode():
    mode = os.environ.get("SECURITY_MODE", "open").lower()
    if mode not in ("open", "enforced"):
        mode = "open"
    return mode

# Security mode snapshot used only for initial startup log; all runtime checks call _current_security_mode()
SECURITY_MODE = _current_security_mode()

# Log initialization (and security mode)
_append_log(f"Semptify initialized with folders: {', '.join(folders)} | security_mode={SECURITY_MODE}")
try:
    # Log a quick inventory of key template & static assets to aid remote diagnostics
    index_tpl = os.path.join(app.template_folder, 'index.html')
    admin_tpl = os.path.join(app.template_folder, 'admin.html')
    manifest_path = os.path.join(app.static_folder, 'manifest.webmanifest')
    _append_log(
        "asset_check "
        f"index_exists={os.path.exists(index_tpl)} "
        f"admin_exists={os.path.exists(admin_tpl)} "
        f"manifest_exists={os.path.exists(manifest_path)}"
    )
except Exception as e:  # pragma: no cover (best effort)
    _append_log(f"asset_check_error {e}")

# -----------------------------
# Security headers middleware
# -----------------------------
@app.after_request
def _set_security_headers(resp):  # pragma: no cover (headers logic simple)
    resp.headers.setdefault('X-Content-Type-Options', 'nosniff')
    resp.headers.setdefault('X-Frame-Options', 'DENY')
    resp.headers.setdefault('Referrer-Policy', 'no-referrer')
    resp.headers.setdefault('X-XSS-Protection', '0')  # modern browsers ignore / CSP recommended
    # Mild default CSP allowing same-origin scripts/styles/images & data: images
    csp = "default-src 'self'; script-src 'self'; style-src 'self'; img-src 'self' data:; object-src 'none'; base-uri 'none'; frame-ancestors 'none'"
    resp.headers.setdefault('Content-Security-Policy', csp)
    # Propagate request id
    rid = getattr(request, 'request_id', None)
    if rid:
        resp.headers.setdefault('X-Request-Id', rid)
    # Optional structured access log (enabled by ACCESS_LOG_JSON=1)
    if os.environ.get('ACCESS_LOG_JSON') == '1':
        try:
            started = getattr(request, '_start_time', None)
            dur_ms = None
            if started is not None:
                dur_ms = int((time.time() - started) * 1000)
            _event_log('access',
                       method=request.method,
                       path=request.full_path.rstrip('?'),
                       status=resp.status_code,
                       ip=request.remote_addr,
                       dur_ms=dur_ms,
                       request_id=rid)
        except Exception as e:  # pragma: no cover
            _append_log(f'access_log_error {e}')
    return resp

@app.before_request
def _access_start():  # pragma: no cover (timing capture)
    # Store start timestamp for latency computation if access logging is enabled
    if os.environ.get('ACCESS_LOG_JSON') == '1':
        request._start_time = time.time()  # pylint: disable=protected-access
    # Generate a request id (idempotent if reverse proxy already set one via header)
    incoming = request.headers.get('X-Request-Id')
    request.request_id = incoming or uuid.uuid4().hex  # type: ignore[attr-defined]

@app.route("/")
def index():
    # Use a Jinja2 template so UI can be extended without changing the route.
    message = "Semptify is live. Buttons coming next."
    _inc('requests_total')
    return render_template("index.html", message=message, folders=folders)


@app.route("/health")
def health():
    _inc('requests_total')
    return "OK", 200

@app.route("/healthz")
def healthz():
    _inc('requests_total')
    return jsonify({
        "status": "ok",
        "time": _utc_now_iso(),
        "folders": folders,
    }), 200

@app.route('/readyz')
def readyz():
    """Readiness probe verifying writable runtime dirs & token file load."""
    _inc('requests_total')
    snapshot, status_ok = _readiness_snapshot()
    return jsonify(snapshot), 200 if status_ok else 503

def _readiness_snapshot():
    """Return (snapshot_dict, healthy_bool)."""
    writable = {}
    for d in folders:
        test_file = os.path.join(d, '.readyz.tmp')
        try:
            with open(test_file, 'w') as f:
                f.write('ok')
            os.remove(test_file)
            writable[d] = True
        except Exception:
            writable[d] = False
    tokens_ok = True
    try:
        _load_tokens(force=True)
    except Exception:
        tokens_ok = False
    status_ok = all(writable.values()) and tokens_ok
    snapshot = {
        'status': 'ready' if status_ok else 'degraded',
        'writable': writable,
        'tokens_load': tokens_ok,
        'time': _utc_now_iso()
    }
    return snapshot, status_ok

def _rate_or_unauth_response():
    """Return a standardized JSON response for rate limited or unauthorized admin access."""
    if getattr(request, '_rate_limited', False):
        return (jsonify({'error': 'rate_limited', 'retry_after': RATE_LIMIT_RETRY_AFTER}),
                RATE_LIMIT_STATUS,
                {'Retry-After': str(RATE_LIMIT_RETRY_AFTER)})
    return jsonify({'error': 'unauthorized'}), 401

@app.errorhandler(500)
def internal_error(e):  # pragma: no cover (framework error path)
    # Provide a lightweight JSON response for API clients while logging root cause
    _append_log(f"ERROR_500 path={request.path} error={e}")
    _event_log('error_500', path=request.path, msg=str(e))
    # If it's a template resolution problem, hint at likely cause
    hint = ''
    if 'TemplateNotFound' in str(e):
        hint = ' (template not found – ensure templates/ directory is deployed)'
    return ("An internal server error occurred" + hint, 500)

@app.route("/version")
def version():
    _inc('requests_total')
    git_sha = os.environ.get("GIT_SHA", "unknown")
    build_time = os.environ.get("BUILD_TIME", "unknown")
    return jsonify({
        "git_sha": git_sha,
        "build_time": build_time,
        "app": "Semptify"
    }), 200

@app.route('/metrics')
def metrics():
    _inc('requests_total')
    txt = _metrics_text()
    return txt, 200, { 'Content-Type': 'text/plain; version=0.0.4' }

@app.route('/info')
def info():
    """Aggregated lightweight info: version + readiness + security mode."""
    _inc('requests_total')
    snapshot, _status = _readiness_snapshot()
    git_sha = os.environ.get("GIT_SHA", "unknown")
    build_time = os.environ.get("BUILD_TIME", "unknown")
    return jsonify({
        'app': 'Semptify',
        'git_sha': git_sha,
        'build_time': build_time,
        'security_mode': _current_security_mode(),
        'readiness': snapshot
    })


TOKENS_CACHE = { 'loaded_at': 0, 'tokens': [], 'path': os.path.join('security','admin_tokens.json'), 'mtime': None }

def _hash_token(raw: str) -> str:
    return 'sha256:' + hashlib.sha256(raw.encode('utf-8')).hexdigest()

def _load_tokens(force: bool=False):
    path = TOKENS_CACHE['path']
    try:
        if not os.path.exists(path):
            if force:
                TOKENS_CACHE['tokens'] = []
            return
        mtime = os.path.getmtime(path)
        if force or TOKENS_CACHE['mtime'] != mtime:
            with open(path,'r') as f:
                data = json.load(f)
            # Normalize
            norm = []
            for entry in data:
                if not entry.get('enabled', True):
                    continue
                h = entry.get('hash')
                if not h:
                    continue
                norm.append({
                    'id': entry.get('id','unknown'),
                    'hash': h,
                    'breakglass': entry.get('breakglass', False)
                })
            TOKENS_CACHE['tokens'] = norm
            TOKENS_CACHE['mtime'] = mtime
    except Exception as e:
        _append_log(f"token_load_error {e}")

def _match_token(raw: str):
    if raw is None:
        return None
    _load_tokens()
    h = _hash_token(raw)
    for t in TOKENS_CACHE['tokens']:
        if t['hash'] == h:
            return t
    return None

def _get_admin_token_legacy():
    # Legacy single-token fallback
    return app.config.get('ADMIN_TOKEN') or os.environ.get('ADMIN_TOKEN', 'devtoken')

def _is_authorized(req) -> bool:
    """Authorization logic with multi-token & optional break-glass.

    open mode: always True.
    enforced: verify against tokens file (hash matches). If no file, fallback to legacy single token.
    break-glass: requires security/breakglass.flag present AND token marked breakglass.
    After successful break-glass use, flag file is removed (one-shot) and event logged.
    """
    if _current_security_mode() == "open":
        return True
    supplied = req.args.get('token') or req.headers.get('X-Admin-Token') or req.form.get('token')
    # Primary multi-token path
    token_entry = _match_token(supplied)
    if token_entry:
        _event_log('admin_auth', method='multi-token', token_id=token_entry['id'], path=req.path, ip=req.remote_addr)
        return True
    # Break-glass path
    flag_path = os.path.join('security','breakglass.flag')
    if os.path.exists(flag_path):
        token_entry = _match_token(supplied)
        if token_entry and token_entry.get('breakglass'):
            try:
                os.remove(flag_path)
            except OSError:
                pass
            _event_log('breakglass_used', token_id=token_entry['id'], path=req.path, ip=req.remote_addr)
            _inc('breakglass_used_total')
            return True
    # Legacy single token fallback (for transitional period)
    legacy = _get_admin_token_legacy()
    if supplied == legacy:
        _event_log('admin_auth', method='legacy-token', token_id='legacy', path=req.path, ip=req.remote_addr)
        return True
    return False

# -----------------------------
# GitHub API helper with retry/backoff (minimal)
# -----------------------------
def _github_request(method: str, url: str, headers: dict, json_payload: Optional[dict] = None, attempts: int = 3, backoff: float = 0.6):
    for i in range(1, attempts + 1):
        try:
            if method == 'GET':
                r = requests.get(url, headers=headers, timeout=10)
            else:
                r = requests.post(url, headers=headers, json=json_payload, timeout=15)
            if r.status_code >= 500 and i < attempts:
                time.sleep(backoff * i)
                continue
            return r
        except requests.RequestException as e:  # pragma: no cover (network failure path)
            if i == attempts:
                raise
            time.sleep(backoff * i)
    # Should not reach here
    raise RuntimeError('github_request_exhausted')

def _simulate_release_for_test(owner: str, repo: str) -> str:
    tag_name = f"vTEST-{_utc_now().strftime('%Y%m%d%H%M%S')}"
    log_path = os.path.join('logs', 'release-log.json')
    entry = { 'tag': tag_name, 'sha': 'testing-sha', 'timestamp': _utc_now_iso(), 'simulated': True }
    try:
        if os.path.exists(log_path):
            with open(log_path, 'r') as f:
                data = json.load(f)
        else:
            data = []
        data.insert(0, entry)
        with open(log_path, 'w') as f:
            json.dump(data, f, indent=2)
    except Exception as e:  # pragma: no cover
        _append_log(f'sim_release_write_fail {e}')
    _append_log(f'Simulated release tag {tag_name} (TESTING mode)')
    _event_log('release_simulated', tag=tag_name)
    return tag_name

def _require_admin_or_401():
    if not _is_authorized(request):
        _append_log(f"UNAUTHORIZED admin attempt path={request.path} ip={request.remote_addr}")
        _event_log('admin_unauthorized', path=request.path, ip=request.remote_addr)
        _inc('errors_total')
        return False
    # Apply rate limiting AFTER auth so attackers do not cause noise with unauth attempts
    rl_key = f"admin:{request.remote_addr}:{request.path}"
    if not _rate_limit(rl_key):
        _append_log(f"RATE_LIMIT path={request.path} ip={request.remote_addr}")
        _event_log('rate_limited', path=request.path, ip=request.remote_addr)
        _inc('errors_total')
        _inc('rate_limited_total')
        # Store marker so caller can translate to proper HTTP status
        request._rate_limited = True  # pylint: disable=protected-access
        return False
    if _current_security_mode() == "open":
        # Still log accesses to admin endpoints while open
        _append_log(f"OPEN_MODE admin access path={request.path} ip={request.remote_addr}")
    _inc('admin_requests_total')
    return True

def _get_or_create_csrf_token():
    token = session.get('_csrf_token')
    if not token:
        token = hashlib.sha256(os.urandom(32)).hexdigest()
        session['_csrf_token'] = token
    return token

def _validate_csrf(req):
    # Only enforce CSRF for state-changing POST requests when enforced mode is active
    if _current_security_mode() != 'enforced':
        return True
    sent = req.form.get('csrf_token') or req.headers.get('X-CSRF-Token')
    token = session.get('_csrf_token')
    if not token or not sent or sent != token:
        _append_log(f"CSRF_FAIL path={req.path} ip={req.remote_addr}")
        _event_log('csrf_fail', path=req.path, ip=req.remote_addr)
        _inc('errors_total')
        return False
    return True


@app.route('/admin', methods=['GET'])
def admin():
    # Simple token check
    if not _require_admin_or_401():
        return _rate_or_unauth_response()

    owner = os.environ.get('GITHUB_OWNER', 'Bradleycrowe')
    repo = os.environ.get('GITHUB_REPO', 'Semptify')
    ci_url = f"https://github.com/{owner}/{repo}/actions"
    pages_url = f"https://{owner}.github.io/{repo}/"
    # Expose token ids (not hashes) for visibility if enforced
    _load_tokens()
    token_ids = [t['id'] + (' (breakglass)' if t.get('breakglass') else '') for t in TOKENS_CACHE['tokens']]
    csrf_token = _get_or_create_csrf_token()
    return render_template('admin.html',
                           ci_url=ci_url,
                           pages_url=pages_url,
                           folders=folders,
                           security_mode=_current_security_mode(),
                           token_ids=token_ids,
                           admin_token=_get_admin_token_legacy(),
                           csrf_token=csrf_token)

@app.route('/admin/status')
def admin_status():
    if not _require_admin_or_401():
        return _rate_or_unauth_response()
    _inc('admin_requests_total')
    _load_tokens()
    token_summaries = [{'id': t['id'], 'breakglass': t.get('breakglass', False)} for t in TOKENS_CACHE['tokens']]
    return jsonify({
        'security_mode': _current_security_mode(),
        'metrics': METRICS,
        'tokens': token_summaries,
        'time': _utc_now_iso()
    })


@app.route('/release_now', methods=['POST'])
def release_now():
    if not _validate_csrf(request):
        return "CSRF validation failed", 400
    if not _require_admin_or_401():
        return _rate_or_unauth_response()

    # Soft confirmation: require hidden field confirm_release=yes
    if request.form.get('confirm_release') != 'yes':
        return abort(400, description="Missing confirmation field")

    github_token = os.environ.get('GITHUB_TOKEN')
    owner = os.environ.get('GITHUB_OWNER', 'Bradleycrowe')
    repo = os.environ.get('GITHUB_REPO', 'Semptify')
    if not github_token:
        # In test mode simulate a successful release so tests can pass without secret
        if app.config.get('TESTING'):
            tag_name = _simulate_release_for_test(owner, repo)
            _inc('releases_total')
            _inc('admin_actions_total')
            return redirect(f'https://github.com/{owner}/{repo}/releases/tag/{tag_name}')
        _append_log('release_now failed: missing GITHUB_TOKEN')
        return "GITHUB_TOKEN not configured on server", 500

    headers = {
        'Authorization': f'token {github_token}',
        'Accept': 'application/vnd.github.v3+json'
    }

    # Get latest commit SHA from default branch (main)
    ref_url = f'https://api.github.com/repos/{owner}/{repo}/git/refs/heads/main'
    r = _github_request('GET', ref_url, headers=headers)
    if r.status_code != 200:
        _append_log(f'release_now failed: cannot read ref: {r.status_code}')
        return f'Failed to read ref: {r.status_code}', 500
    sha = r.json().get('object', {}).get('sha')

    # Create a timestamped tag
    tag_name = f'v{_utc_now().strftime("%Y%m%d%H%M%S")}'
    create_ref_url = f'https://api.github.com/repos/{owner}/{repo}/git/refs'
    payload = { 'ref': f'refs/tags/{tag_name}', 'sha': sha }
    r = _github_request('POST', create_ref_url, headers=headers, json_payload=payload)
    if r.status_code in (201, 200):
        _append_log(f'Created tag {tag_name} via API')
        _event_log('release_created', tag=tag_name, sha=sha, ip=request.remote_addr)
        _inc('releases_total')
        _inc('admin_actions_total')
        # record release in release-log.json
        log_path = os.path.join('logs', 'release-log.json')
        entry = { 'tag': tag_name, 'sha': sha, 'timestamp': _utc_now_iso() }
        try:
            if os.path.exists(log_path):
                with open(log_path, 'r') as f:
                    data = json.load(f)
            else:
                data = []
            data.insert(0, entry)
            with open(log_path, 'w') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            _append_log(f'Failed to write release-log.json: {e}')

        return redirect(f'https://github.com/{owner}/{repo}/releases/tag/{tag_name}')
    else:
        _append_log(f'Failed to create tag: {r.status_code} {r.text}')
        return f'Failed to create tag: {r.status_code}', 500


@app.route('/trigger_workflow', methods=['POST'])
def trigger_workflow():
    if not _validate_csrf(request):
        return "CSRF validation failed", 400
    if not _require_admin_or_401():
        return _rate_or_unauth_response()

    if request.form.get('confirm_trigger') != 'yes':
        return abort(400, description="Missing confirmation field")

    workflow = request.form.get('workflow', 'ci.yml')
    ref = request.form.get('ref', 'main')
    github_token = os.environ.get('GITHUB_TOKEN')
    owner = os.environ.get('GITHUB_OWNER', 'Bradleycrowe')
    repo = os.environ.get('GITHUB_REPO', 'Semptify')
    if not github_token:
        return "GITHUB_TOKEN not configured", 500

    headers = { 'Authorization': f'token {github_token}', 'Accept': 'application/vnd.github.v3+json' }
    dispatch_url = f'https://api.github.com/repos/{owner}/{repo}/actions/workflows/{workflow}/dispatches'
    payload = { 'ref': ref }
    r = requests.post(dispatch_url, headers=headers, json=payload)
    if r.status_code in (204, 201):
        _append_log(f'Triggered workflow {workflow} on {ref}')
        _event_log('workflow_dispatch', workflow=workflow, ref=ref, ip=request.remote_addr)
        _inc('admin_actions_total')
        return redirect(f'https://github.com/{owner}/{repo}/actions')
    else:
        _append_log(f'Failed to trigger workflow {workflow}: {r.status_code} {r.text}')
        return f'Failed to trigger workflow: {r.status_code}', 500


@app.route('/release_history')
def release_history():
    if not _require_admin_or_401():
        return _rate_or_unauth_response()
    _inc('admin_requests_total')
    log_path = os.path.join('logs', 'release-log.json')
    if os.path.exists(log_path):
        with open(log_path, 'r') as f:
            data = json.load(f)
    else:
        data = []
    return render_template('release_history.html', data=data)


@app.route('/sbom')
def sbom_list():
    if not _require_admin_or_401():
        return _rate_or_unauth_response()
    _inc('admin_requests_total')
    sbom_dir = os.path.join('.', 'sbom')
    files = []
    if os.path.exists(sbom_dir):
        files = sorted(os.listdir(sbom_dir), reverse=True)
    supplied = request.args.get('token') or request.form.get('token') or request.headers.get('X-Admin-Token')
    return render_template('sbom_list.html', files=files, token=supplied)

@app.route('/sbom/<path:filename>')
def sbom_get(filename):
    if not _require_admin_or_401():
        return _rate_or_unauth_response()
    _inc('admin_requests_total')
    sbom_dir = os.path.join('.', 'sbom')
    path = os.path.join(sbom_dir, filename)
    if os.path.exists(path):
        return send_file(path, as_attachment=True)
    return "Not found", 404

@app.route('/offline')
def offline():
    # Simple offline fallback route (also cached by SW if added there)
    _inc('requests_total')
    return "You are offline. Limited functionality.", 200, { 'Content-Type': 'text/plain' }

# -----------------------------
# Token rotation endpoint
# -----------------------------
def _write_tokens(tokens: list):
    path = TOKENS_CACHE['path']
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, 'w') as f:
            json.dump(tokens, f, indent=2)
        # force reload
        _load_tokens(force=True)
    except Exception as e:
        _append_log(f"token_write_error {e}")

@app.route('/rotate_token', methods=['POST'])
def rotate_token():
    if not _validate_csrf(request):
        return "CSRF validation failed", 400
    if not _require_admin_or_401():
        return _rate_or_unauth_response()
    # current auth token already validated; now require target id & new token value
    target_id = request.form.get('target_id')
    new_value = request.form.get('new_value')
    if not target_id or not new_value:
        return "Missing target_id or new_value", 400
    path = TOKENS_CACHE['path']
    if not os.path.exists(path):
        return "Token file missing", 400
    try:
        with open(path, 'r') as f:
            data = json.load(f)
    except Exception as e:
        return f"Failed to read tokens: {e}", 500
    found = False
    for entry in data:
        if entry.get('id') == target_id:
            entry['hash'] = _hash_token(new_value)
            found = True
            break
    if not found:
        return "Target token id not found", 404
    _write_tokens(data)
    _event_log('token_rotated', token_id=target_id, ip=request.remote_addr)
    _inc('token_rotations_total')
    return redirect('/admin')

if __name__ == "__main__":
    app.run(debug=True)

```

## .releaserc.json
```
{
  "branches": ["main"],
  "repositoryUrl": "https://github.com/Bradleycrowe/Semptify"
}

```

## docs\index.html
```
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Semptify Demo</title>
  </head>
  <body>
    <h1>Semptify</h1>
    <p>Demo page for the project. This repository includes a small Flask app; see README for run instructions.</p>
  </body>
</html>

```

## docker-compose.yml
```
version: "3.8"
services:
  semptify:
    build: .
    ports:
      - "8080:8080"
    environment:
      - SEMPTIFY_PORT=8080
    volumes:
      - ./uploads:/app/uploads
      - ./final_notices:/app/final_notices
      - ./logs:/app/logs
    restart: unless-stopped

```

## .dockerignore
```
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
.env
.venv
venv/
build/
dist/
*.egg-info
*.egg
uploads/
logs/
copilot_sync/
final_notices/
security/
sbom/
.pytest_cache/
.git
.gitignore
docs/
.releaserc.json
*.md

```

## Dockerfile
```
# Multi-stage Dockerfile
FROM python:3.13-slim AS builder
ARG GIT_SHA="dev"
ARG BUILD_TIME="unknown"
WORKDIR /app

# Install build/test dependencies and app requirements (cached separately from source)
COPY requirements.txt ./
RUN pip install --upgrade pip && \
	pip install --no-cache-dir -r requirements.txt

# Copy source for testing
COPY . /app

# Install pytest and run tests during the build to fail fast (fail = stop image build early)
RUN pip install --no-cache-dir pytest && pytest -q tests

### Final image (runtime)
FROM python:3.13-slim AS runtime
ARG GIT_SHA="dev"
ARG BUILD_TIME="unknown"
ENV GIT_SHA=${GIT_SHA} \
	BUILD_TIME=${BUILD_TIME}
WORKDIR /app

# Copy pre-installed dependencies from builder to avoid re-install (smaller & faster)
COPY --from=builder /usr/local/lib/python3.13/site-packages /usr/local/lib/python3.13/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy only necessary application code (exclude caches & tests for smaller runtime image)
COPY . /app
RUN rm -rf /app/tests /app/__pycache__ || true

EXPOSE 8080
CMD ["python", "./run_prod.py"]

```

## RUNNING_PRODUCTION.md
```
# Production runner and deployment notes

This project is a small Flask app. The development server (`app.run(debug=True)`) is suitable for development only. Use the included `run_prod.py` with a production WSGI server.

Quick start (venv active):

```powershell
pip install -r requirements.txt
# Run on port 8080 (binds all interfaces)
$env:SEMPTIFY_PORT=8080
python .\run_prod.py
```

Environment variables

- `SEMPTIFY_HOST` — host to bind (default: `0.0.0.0`)
- `SEMPTIFY_PORT` — port to listen on (default: `8080`)

Notes

- `security/` may contain keys or secrets. Mount secrets at runtime; do not commit them to git.
- The app writes to disk; configure persistent storage for `uploads/`, `final_notices/`, and `logs/` in production.
- Consider placing the app behind a reverse proxy (nginx, IIS) for TLS, rate limiting, and static asset serving.

## Docker (recommended for small deployments)

Build the image locally:

```powershell
Set-Location -LiteralPath 'd:\Semptify\Semptify'
docker build -t Semptify:latest .
```

Run with Docker (bind port 8080):

```powershell
docker run --rm -p 8080:8080 \
  -v ${PWD}:/app \
  -v ${PWD}\\uploads:/app/uploads \
  -v ${PWD}\\logs:/app/logs \
  Semptify:latest
```

Or use docker-compose:

```powershell
docker-compose up --build
```

Notes:

- `.dockerignore` excludes runtime and secret folders from the build context.
- Volumes in `docker-compose.yml` map runtime folders to host for persistence and inspection.

```

## run_prod.py
```
import os
from waitress import serve
from Semptify import app

if __name__ == '__main__':
    # Read host/port from environment with sane defaults
    # Accept both custom SEMPTIFY_PORT and platform-provided PORT (Render/Heroku style)
    host = os.environ.get('SEMPTIFY_HOST', '0.0.0.0')
    port = int(os.environ.get('SEMPTIFY_PORT') or os.environ.get('PORT', '8080'))

    # Ensure runtime folders exist (app already does this on import but keep-safe)
    folders = ["uploads", "logs", "copilot_sync", "final_notices", "security"]
    for folder in folders:
        if not os.path.exists(folder):
            os.makedirs(folder)

    print(f"Starting Semptify (production) on {host}:{port} (PORT env fallback supported)")
    serve(app, host=host, port=port)

```

## templates\sbom_list.html
```
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>SBOMs</title>
  </head>
  <body>
    <h1>SBOM files</h1>
    <ul>{% for f in files %}
      <li><a href="/sbom/{{ f }}{% if token %}?token={{ token }}{% endif %}">{{ f }}</a></li>
    {% endfor %}</ul>
    <p><a href="/admin{% if token %}?token={{ token }}{% endif %}">Back</a></p>
  </body>
</html>

```

## templates\release_history.html
```
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Release History</title>
  </head>
  <body>
    <h1>Release History</h1>
    <ul>{% for r in data %}<li>{{ r.tag }} - {{ r.sha }} - {{ r.timestamp }}</li>{% endfor %}</ul>
    <p><a href="/admin?token=devtoken">Back</a></p>
  </body>
</html>

```

## tests\test_breakglass_and_ratelimit.py
```
import os, json, importlib, time

# We'll simulate enforced mode with a break-glass token

def setup_tokens(tmpdir):
    os.environ['SECURITY_MODE'] = 'enforced'
    os.environ['ADMIN_RATE_WINDOW'] = '2'
    os.environ['ADMIN_RATE_MAX'] = '3'
    # legacy token for fallback clarity
    os.environ['ADMIN_TOKEN'] = 'legacytok'
    sec_dir = os.path.join(tmpdir, 'security')
    os.makedirs(sec_dir, exist_ok=True)
    # create break-glass file
    open(os.path.join(sec_dir, 'breakglass.flag'), 'w').close()
    # create tokens file with breakglass token
    import hashlib
    bg_hash = 'sha256:' + hashlib.sha256(b'glass123').hexdigest()
    with open(os.path.join(sec_dir, 'admin_tokens.json'), 'w') as f:
        json.dump([{ 'id': 'bg', 'hash': bg_hash, 'enabled': True, 'breakglass': True }], f)
    os.chdir(tmpdir)
    import Semptify as sempt
    importlib.reload(sempt)
    sempt.app.config['TESTING'] = True
    return sempt

def test_breakglass_one_shot_and_rate_limit(tmp_path):
    sempt = setup_tokens(str(tmp_path))
    client = sempt.app.test_client()
    # Use breakglass token first time (flag exists)
    r1 = client.get('/admin?token=glass123')
    assert r1.status_code == 200
    assert b'ENFORCED' in r1.data
    # Second time should still work (now normal multi-token since token is in file) but breakglass flag consumed
    r2 = client.get('/admin?token=glass123')
    assert r2.status_code == 200
    # Hit same admin path to trigger rate limiting (limit=3/window)
    client.get('/admin?token=glass123')
    client.get('/admin?token=glass123')
    rlim = client.get('/admin?token=glass123')
    # After exceeding, we expect 401 from _require_admin_or_401 returning False due to rate limit (current impl)
    assert rlim.status_code in (401, 429)
    metrics = client.get('/metrics').data.decode()
    assert 'rate_limited_total' in metrics
    assert 'breakglass_used_total' in metrics

```

## templates\index.html
```
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Semptify</title>
  </head>
  <body>
    <h1>{{ message }}</h1>
    <p>Available runtime folders:</p>
    <ul>
      {% for f in folders %}
      <li>{{ f }}</li>
      {% endfor %}
    </ul>
  </body>
</html>

```

## templates\admin.html
```
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
  <title>Semptify Admin</title>
  <link rel="stylesheet" href="/static/css/admin.css" />
  </head>
  <body>
    <h1>Semptify Admin</h1>
    {% if security_mode == 'open' %}
      <div class="banner banner-open">SECURITY MODE: OPEN (no admin token enforcement). Do not use in production.</div>
    {% else %}
      <div class="banner banner-enforced">SECURITY MODE: ENFORCED</div>
      {% if token_ids %}
        <p><strong>Active Token IDs:</strong> {{ token_ids|join(', ') }}</p>
        <p><small>Break-glass requires file <code>security/breakglass.flag</code> + a breakglass token.</small></p>
        <form action="/rotate_token" method="post" class="rotate-form">
          <fieldset>
            <legend>Rotate Token</legend>
            <label>Token ID: <input name="target_id" placeholder="primary" required></label>
            <label>New Value: <input name="new_value" required></label>
            <input type="hidden" name="token" value="{{ admin_token }}">
            <input type="hidden" name="csrf_token" value="{{ csrf_token }}">
            <button type="submit" onclick="return confirm('Rotate this token now?');">Rotate</button>
          </fieldset>
        </form>
      {% endif %}
    {% endif %}
    <p><a href="{{ ci_url }}" target="_blank">View CI dashboard</a></p>
    <p><a href="{{ pages_url }}" target="_blank">View Pages site</a></p>

    <form action="/release_now" method="post" onsubmit="return confirmRelease(this);">
      <input type="hidden" name="token" value="{{ admin_token }}">
      <input type="hidden" name="confirm_release" value="yes">
      <input type="hidden" name="csrf_token" value="{{ csrf_token }}">
      <button type="submit">Release Now</button>
    </form>

    <form action="/trigger_workflow" method="post" onsubmit="return confirmTrigger(this);">
      <input type="hidden" name="token" value="{{ admin_token }}">
      <input type="hidden" name="confirm_trigger" value="yes">
      <input type="hidden" name="csrf_token" value="{{ csrf_token }}">
      <label>Workflow file: <input name="workflow" value="ci.yml"></label>
      <label>ref: <input name="ref" value="main"></label>
      <button type="submit">Trigger CI</button>
    </form>

  <p><a href="/release_history?token={{ admin_token }}">View Release History</a></p>
  <p><a href="/sbom?token={{ admin_token }}">View SBOMs</a></p>
  <script>
    function confirmRelease(form){
      return confirm('Confirm creating a release tag now?');
    }
    function confirmTrigger(form){
      return confirm('Trigger the specified workflow now?');
    }
  </script>
  </body>
</html>

```

## tests\test_token_rotation.py
```
import os, importlib, json, re, tempfile

def setup_enforced(tmpdir):
    os.environ['SECURITY_MODE'] = 'enforced'
    os.environ['ADMIN_TOKEN'] = 'rotsecret'
    security_dir = os.path.join(tmpdir, 'security')
    os.makedirs(security_dir, exist_ok=True)
    # Create tokens file with one entry
    token_hash = 'sha256:' + __import__('hashlib').sha256(b'rotsecret').hexdigest()
    with open(os.path.join(security_dir, 'admin_tokens.json'), 'w') as f:
        json.dump([{ 'id': 'primary', 'hash': token_hash, 'enabled': True }], f)
    # Point app to this custom security path by chdir
    os.chdir(tmpdir)
    import Semptify as sempt
    importlib.reload(sempt)
    sempt.app.config['TESTING'] = True
    return sempt

def extract_csrf(html: str):
    m = re.search(r'name="csrf_token" value="([0-9a-f]+)"', html)
    assert m, 'csrf token missing'
    return m.group(1)

def test_token_rotation_flow(tmp_path):
    sempt = setup_enforced(str(tmp_path))
    client = sempt.app.test_client()
    admin_page = client.get('/admin?token=rotsecret')
    csrf = extract_csrf(admin_page.data.decode())
    resp = client.post('/rotate_token', data={
        'token': 'rotsecret',
        'csrf_token': csrf,
        'target_id': 'primary',
        'new_value': 'newrotsecret'
    }, follow_redirects=False)
    assert resp.status_code in (301,302)
    # Ensure metrics updated
    metrics = client.get('/metrics')
    assert b'token_rotations_total' in metrics.data

```

## tests\test_csrf_enforced.py
```
import os, importlib, re

def setup_enforced():
    os.environ['SECURITY_MODE'] = 'enforced'
    os.environ['ADMIN_TOKEN'] = 'csrfsecret'
    import Semptify as sempt
    importlib.reload(sempt)
    sempt.app.config['TESTING'] = True
    return sempt

def extract_csrf(html: str):
    m = re.search(r'name="csrf_token" value="([0-9a-f]+)"', html)
    assert m, 'csrf token not found in admin page html'
    return m.group(1)

def test_missing_csrf_rejected():
    sempt = setup_enforced()
    client = sempt.app.test_client()
    # Prime session & get page
    client.get('/admin?token=csrfsecret')
    # Attempt POST without csrf
    resp = client.post('/release_now', data={'token': 'csrfsecret', 'confirm_release': 'yes'})
    assert resp.status_code == 400

def test_valid_csrf_allows_release_tag(monkeypatch):
    sempt = setup_enforced()
    client = sempt.app.test_client()
    page = client.get('/admin?token=csrfsecret')
    csrf = extract_csrf(page.data.decode())

    # Monkeypatch GitHub API calls used in release_now
    class DummyResp:
        def __init__(self, status_code, json_data=None, text=''):
            self.status_code = status_code
            self._json = json_data or {}
            self.text = text
        def json(self):
            return self._json
    def fake_get(url, headers=None):
        return DummyResp(200, {'object': {'sha': 'abc123'}})
    def fake_post(url, headers=None, json=None):
        return DummyResp(201, {})
    monkeypatch.setattr('requests.get', fake_get)
    monkeypatch.setattr('requests.post', fake_post)

    resp = client.post('/release_now', data={
        'token': 'csrfsecret',
        'csrf_token': csrf,
        'confirm_release': 'yes'
    }, follow_redirects=False)
    # Should redirect to github releases (302)
    assert resp.status_code in (301,302)

```

## tests\test_admin_status.py
```
import os, importlib, json

def setup_enforced():
    os.environ['SECURITY_MODE'] = 'enforced'
    os.environ['ADMIN_TOKEN'] = 'statustoken'
    import Semptify as sempt
    importlib.reload(sempt)
    sempt.app.config['TESTING'] = True
    return sempt

def test_admin_status_json():
    sempt = setup_enforced()
    client = sempt.app.test_client()
    # unauthorized first
    r1 = client.get('/admin/status')
    assert r1.status_code == 401
    # authorized
    r2 = client.get('/admin/status?token=statustoken')
    assert r2.status_code == 200
    data = r2.get_json()
    assert 'security_mode' in data and data['security_mode'] == 'enforced'
    assert 'metrics' in data and isinstance(data['metrics'], dict)
    assert 'tokens' in data

```

## tests\test_admin_enforced_mode.py
```
import os
import importlib

def test_admin_enforced_requires_token():
    os.environ['SECURITY_MODE'] = 'enforced'
    os.environ['ADMIN_TOKEN'] = 'secret123'
    import Semptify as sempt
    importlib.reload(sempt)
    sempt.app.config['TESTING'] = True
    client = sempt.app.test_client()
    # Missing token -> 401
    resp1 = client.get('/admin')
    assert resp1.status_code == 401
    # With token -> 200
    resp2 = client.get('/admin?token=secret123')
    assert resp2.status_code == 200
    assert b'SECURITY MODE: ENFORCED' in resp2.data
```

## tests\test_admin_open_mode.py
```
import os
from Semptify import app


def test_admin_open_mode_access():
    # Force open mode explicitly
    os.environ['SECURITY_MODE'] = 'open'
    app.config['TESTING'] = True
    with app.test_client() as client:
        rv = client.get('/admin')
        assert rv.status_code == 200
        assert b'SECURITY MODE: OPEN' in rv.data

```

## tests\test_app.py
```
import os
import tempfile
import pytest
from Semptify import app

@pytest.fixture
def client():
    app.config['TESTING'] = True
    with app.test_client() as client:
        yield client

def test_index(client):
    rv = client.get('/')
    assert rv.status_code == 200
    assert b"Semptify is live" in rv.data

```

## .pytest_cache\CACHEDIR.TAG
```
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html

```

## .pytest_cache\README.md
```
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

```

## templates\Saved Games\desktop.ini
```
[.ShellClassInfo]
LocalizedResourceName=@%SystemRoot%\system32\shell32.dll,-21814

```

## .pytest_cache\v\cache\lastfailed
```
{}
```

## .pytest_cache\v\cache\nodeids
```
[
  "tests/test_admin.py::test_admin_unauthorized",
  "tests/test_admin.py::test_release_now_and_trigger_workflow",
  "tests/test_admin_enforced_mode.py::test_admin_enforced_requires_token",
  "tests/test_admin_open_mode.py::test_admin_open_mode_access",
  "tests/test_admin_status.py::test_admin_status_json",
  "tests/test_app.py::test_index",
  "tests/test_breakglass_and_ratelimit.py::test_breakglass_one_shot_and_rate_limit",
  "tests/test_csrf_enforced.py::test_missing_csrf_rejected",
  "tests/test_csrf_enforced.py::test_valid_csrf_allows_release_tag",
  "tests/test_token_rotation.py::test_token_rotation_flow"
]
```

## README.md
```
# Semptify

![CI](https://github.com/Bradleycrowe/Semptify/actions/workflows/ci.yml/badge.svg)
![Pages](https://github.com/Bradleycrowe/Semptify/actions/workflows/pages.yml/badge.svg)

Small Flask-based GUI for tenant-justice automation. This repository includes a development server, a production runner (`run_prod.py` using waitress), Docker support, tests, and CI workflows.

Getting started (development)

```powershell
Set-Location -LiteralPath 'd:\Semptify\Semptify'
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
python .\Semptify.py
```

Running in production (waitress)

```powershell
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
python .\run_prod.py
```

Docker

```powershell
docker build -t Semptify:latest .
docker run --rm -p 8080:8080 Semptify:latest
```

Tests

```powershell
.\.venv\Scripts\Activate.ps1
pip install pytest
python -m pytest -q
```

CI and Releases

- GitHub Actions runs tests and builds images on push/PR.
- On tag pushes the workflow scans the image with Trivy, generates an SBOM with Syft, publishes images to GHCR (and optionally Docker Hub), and creates a GitHub Release with artifacts (image-info, SBOM, Trivy SARIF).

If you need me to add deploy manifests (Kubernetes/Helm) or automated tagging, tell me and I will add them.

## Test Mode Release Simulation

In test mode (Flask `app.config['TESTING']=True`) when `GITHUB_TOKEN` is absent, `/release_now` creates a simulated tag (`vTEST-<timestamp>`) locally and records it in `logs/release-log.json` with `"simulated": true` instead of calling the GitHub API.

## Security Modes

`SECURITY_MODE` controls admin protection:

- `open` (default): Admin routes do not require the `ADMIN_TOKEN`, but each access is logged with an `OPEN_MODE` entry.
- `enforced`: Admin routes require the `ADMIN_TOKEN` (passed as `?token=...` or `X-Admin-Token` header).

Change mode by setting the environment variable before starting the app or updating the Render service env vars.

### Multi-Token & Break-Glass (Advanced)

Create `security/admin_tokens.json` (not committed) with entries:

```jsonc
[
  { "id": "primary", "hash": "sha256:<hash-of-token>", "enabled": true },
  { "id": "ops-breakglass", "hash": "sha256:<hash-of-token>", "enabled": true, "breakglass": true }
]
```

Generate a hash (PowerShell example):

```powershell
$raw = 'SuperSecretTokenValue'
$hash = (python - <<'PY'
import hashlib,os
print('sha256:' + hashlib.sha256(os.environ['RAW'].encode()).hexdigest())
PY
)
```

Or via Python directly in a REPL:

```python
import hashlib
print('sha256:' + hashlib.sha256(b'SuperSecretTokenValue').hexdigest())
```

Break-glass activation: create an empty file `security/breakglass.flag` on the server. The next request using a token marked `"breakglass": true` will authenticate and remove the flag (one-shot). All events append structured JSON lines in `logs/events.log`.

### CSRF Protection (Enforced Mode)

When `SECURITY_MODE=enforced`, all state-changing admin POST routes (`/release_now`, `/trigger_workflow`, `/rotate_token`) require a valid session CSRF token:

1. Browser (or test client) first performs a GET to `/admin` with a valid admin token to establish a session.
2. A hidden field `csrf_token` is included in the admin forms.
3. POST requests missing or with an invalid CSRF token return `400 CSRF validation failed`.

In `open` mode CSRF validation is skipped to keep friction low during early adoption / public demo.

### Rate Limiting

Admin routes apply a sliding-window rate limit (default 60 requests / 60 seconds / (IP, path) tuple). Configure via env vars:

yADMIN_RATE_STATUS=429  # HTTP status for limited requests (override if an upstream expects 503)
```
ADMIN_RATE_WINDOW=60    # window seconds
ADMIN_RATE_MAX=60       # max requests per window
ADMIN_RATE_STATUS=429   # HTTP status for limited requests (override if an upstream expects 503)
ADMIN_RATE_RETRY_AFTER=60 # (optional) seconds clients should wait before retry (defaults to ADMIN_RATE_WINDOW)
```

When exceeded the attempt is logged (`rate_limited`) and increments `rate_limited_total`. Responses now include:

```jsonc
{
  "error": "rate_limited",
  "retry_after": 60
}
```

And a `Retry-After` header with the same number of seconds. Unauthorized admin attempts return:

```json
{ "error": "unauthorized" }
```

HTML admin UI accesses still render templates; API/automation clients should inspect status codes (401 vs 429/ configured) and JSON body.

### Readiness Endpoint

`/readyz` performs writable checks for runtime directories and (if present) attempts to load the token file. Returns 200 with `{ "status": "ready" }` on success, or 503 with `{ "status": "degraded" }` if any directory is not writable or tokens fail to load.

### Extended Metrics

The `/metrics` endpoint (Prometheus plaintext) now exposes counters with HELP/TYPE preambles:

- `requests_total`
- `admin_requests_total`
- `admin_actions_total` (mutating operations)
- `errors_total`
- `releases_total`
- `rate_limited_total`
- `breakglass_used_total`
- `token_rotations_total`
 - `uptime_seconds` (gauge)

### Admin Status Endpoint

`/admin/status` (GET) returns a JSON snapshot (requires auth in enforced mode):

```jsonc
{
  "security_mode": "enforced",
  "metrics": { "requests_total": 42, ... },
  "tokens": [ { "id": "primary", "breakglass": false } ],
  "time": "2025-10-08T12:34:56.789Z"
}
```

### Token Rotation

### Unified Info Endpoint

`/info` returns aggregated metadata (app, git SHA, build time), current security mode, and readiness snapshot in one call for dashboards.

### Structured Access Logging

Enable JSON access logs (one line per request) by setting `ACCESS_LOG_JSON=1`. Each entry includes method, path, status, IP, latency (ms), and `request_id`.

### Request Correlation

Each request receives an `X-Request-Id` header (preserved if a proxy already supplies one). Access log entries include this `request_id` for log correlation.

### Vulnerability Allowlist

Add an optional `security/vuln_allowlist.json` (example provided) to suppress known, time‑bounded CVEs in the vuln delta workflow. Suppressed counts appear in delta output (`new_effective`).

Rotate an existing entry in `security/admin_tokens.json` via the admin UI Rotate Token form. This updates the token hash atomically and increments `token_rotations_total`. (In enforced mode, CSRF + admin token are both required.)

## Render Deployment

The `render.yaml` describes the service. Key env vars:

- `SEMPTIFY_PORT`: internal port (default 8080)
- `ADMIN_TOKEN`: only required once you switch to enforced mode
- `SECURITY_MODE`: `open` or `enforced`

After a push to `main`, Render auto deploys (if configured). Health check: `/health`.

### Post-Deploy Smoke Test

Use the provided PowerShell script:

```powershell
./RenderSmokeTest.ps1 -BaseUrl https://Semptify.onrender.com
```

If in enforced mode:

```powershell
RenderSmokeTest.ps1 -BaseUrl https://Semptify.onrender.com -AdminToken YOUR_ADMIN_TOKEN
```

Outputs will confirm health, version metadata, and admin banner (OPEN or ENFORCED).

### Sample Admin Automation (CI / Status Polling)

Poll `/admin/status` for real-time dashboards:

```powershell
Invoke-RestMethod "https://<your-app>/admin/status?token=$env:ADMIN_TOKEN" | ConvertTo-Json -Depth 4
```

### Offline / PWA Support

The app ships a service worker + manifest, maskable icon, and dark/light theme toggle. The `/offline` route serves a fallback message when the network is unavailable. Future iterations may add richer offline caching (admin read-only panel).

---

## Roadmap (Open Doors → Fully Functional)

- [x] Multi-token & break-glass auth
- [x] CSRF protection (enforced mode)
- [x] Rate limiting + metrics
- [x] Structured event logging
- [x] PWA manifest + service worker offline fallback
- [ ] Rich offline admin panel subset (read-only)
- [ ] SBOM diff alerting
- [ ] Semantic version tagging automation
- [ ] Expanded test coverage for security edge cases

Contributions or feature requests: open an issue or describe the desired end-user workflow and the automation you want.

## Open Doors Checklist

Validate these before public production exposure:

1. **Secrets & Auth**
   - FLASK_SECRET strong random
   - Multi-token file present (if enforced) and stored securely
   - GITHUB_TOKEN configured (if using release UI)
2. **Security Mode**
   - SECURITY_MODE explicitly set (avoid implicit default)
3. **Rate Limiting**
   - ADMIN_RATE_WINDOW / ADMIN_RATE_MAX tuned
4. **Observability**
   - /metrics scraped; logs/events.log ingestion working
5. **Supply Chain**
   - Trivy scan passes (no unresolved CRITICAL/HIGH)
   - SBOM artifact attached; diff reviewed
6. **PWA / UX**
   - Icons + manifest valid; offline route reachable
7. **Admin Ops**
   - /admin/status returns healthy snapshot
   - Token rotation and (if needed) break-glass validated
8. **Health & Readiness**
   - /health, /healthz, /readyz 200 (simulate a failure to observe 503)
9. **Backups**
   - Secure copy of token file & essential logs (policy permitting)
10. **Automation**
    - Post-deploy smoke workflow green

## Environment Configuration

An `.env.example` file documents common variables. For local development:

```bash
cp .env.example .env
```

The app auto-loads `.env` at import time (without overriding already-set environment variables). Never commit real secrets.

## WSL Quick Setup

You can bootstrap a working Semptify environment inside Ubuntu on WSL2 with the helper script:

```bash
bash scripts/wsl_setup.sh            # basic Python env
bash scripts/wsl_setup.sh --force-venv  # recreate venv if needed
bash scripts/wsl_setup.sh --with-docker # also install Docker Engine (optional)
```

The script will:

1. Install required apt packages (python3, venv, build tools, git).
2. Clone or update this repository.
3. Create / reuse a `.venv` and install `requirements.txt`.
4. Run a light smoke test subset.
5. Print next‑step commands for dev (`python Semptify.py`) or prod (`python run_prod.py`).

Environment variables for security modes (examples):

```bash
export SECURITY_MODE=open
export ADMIN_TOKEN=changeme
export FLASK_SECRET=$(python - <<PY
import secrets; print(secrets.token_hex(32))
PY
)
```

If you pass `--with-docker`, the script installs Docker Engine under WSL; log out/in (or restart WSL) to activate group membership.

### Windows Wrapper

From PowerShell you can call a convenience wrapper instead of remembering bash flags:

```powershell
pwsh ./scripts/wsl_setup.ps1 -WithDocker -ForceVenv -Dir /mnt/d/Semptify/Semptify
```

### Docker Verification inside WSL

After enabling Docker (and restarting WSL session):

```bash
bash scripts/wsl_docker_verify.sh
```

It pulls `hello-world`, prints a short run excerpt, and (if the repo has a `Dockerfile`) builds a local image `Semptify:local`.

### GitHub Codespaces / Dev Container

This repo includes a `.devcontainer/devcontainer.json` for a ready-to-code environment:

What happens on creation:

1. Base image: `mcr.microsoft.com/devcontainers/python:3.13`.
2. Installs requirements.
3. Runs pytest (non-fatal if failures) for quick feedback.
4. Provides Pylance + Python extensions.


To use locally with VS Code + Dev Containers extension:

1. Install the Dev Containers extension.
2. Command Palette: "Dev Containers: Reopen in Container".
3. On first build it seeds dependencies and runs the smoke tests.

Environment variables (e.g. `SECURITY_MODE`, `ADMIN_TOKEN`) can be added via a `.env` file or the devcontainer JSON `containerEnv` property if needed.


```

## security\vuln_allowlist.example.json
```
[
  {
    "cve": "CVE-YYYY-XXXX",
    "reason": "Library X used transiently; patch pending upstream",
    "expires": "2025-12-31"
  }
]

```

## logs\release-log.json
```
[
  {
    "tag": "vTEST-20251009052231",
    "sha": "testing-sha",
    "timestamp": "2025-10-09T05:22:31.480012",
    "simulated": true
  }
]
```


